{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "955bb4cd-d359-425b-8eaf-7a32d833160e",
   "metadata": {},
   "source": [
    "(pago)=\n",
    "# Acceso a IA con m√©todos de pago\n",
    "\n",
    "A lo largo de la mayor parte de los apartados que se desarrollan en todos los apartados mostrados  en este trabajo, los procedimientos se han desarrollado de tal manera que no se procediera a ning√∫n tipo de gasto.\n",
    "\n",
    "No obstante existen en el mercado diferentes plataformas que por supuesto ofrecen mejores prestaciones que el trabajo en el ordenador local y que para ello se requiere hacer frente a alg√∫n tipo de gasto. En este apartado se va a mostrar c√≥mo pode hacer estos en dos de las m√°s usadas en el actual mercado:\n",
    "\n",
    "* OpenAI\n",
    "\n",
    "* DeepSeek\n",
    "\n",
    "## OpenAI.\n",
    "\n",
    "Esta plataforma es una de las pioneras en el sector y para poder operar con ella se debe obtener en primer lugar la denominada api-key en la siguiente direcci√≥n web (una vez que el usuario se ha logueado en el sistema):\n",
    "\n",
    "https://platform.openai.com/settings/organization/api-keys\n",
    "\n",
    "La api-key que se obtiene debe guardarse en un fichero del ordenador personal, ya que posteriormente no se puede ver.\n",
    "\n",
    "Esta ap√≠ key es la que se utilizar√° posteriormente cuando se llame al trabajo correspondiente de inteligencia artificial. Dado que esta clave es individual, conviene que la misma no sea visible en el c√≥digo, y para ello existen diferentes procedimientos:\n",
    "\n",
    "* Guardarla en un fichero de texto y despu√©s en el c√≥digo leer ese fichero y la clave correspondiente.\n",
    "\n",
    "* Crear un fichero con extensi√≥n .py (fichero de c√≥digo python) y all√≠ crear una variable que contenga la api-key para despu√©s importar ese fichero .py desde nuestro fichero de c√≥digo y as√≠ poder entresacar el api-key sin que nadie que lea el c√≥digo pueda as√≠ conocer esa clave\n",
    "\n",
    "* Guardar la clave en una variable de entorno, y despu√©s desde el c√≥digo poder leer esa variable de entorno.\n",
    "\n",
    "Nosotros y para este trabajo, vamos a proceder seg√∫n lo indicado en el primer apartado, y para ello creamos el fichero denominado clave_openai.txt y dentro de ese fichero introducimos la api-key obtenida.\n",
    "\n",
    "Ahora que ya tenemos todo dispuesto de esta manera, nos podemos conectar con OpenAI con el siguiente c√≥digo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ab09b56-22da-4b62-a543-41d69ef1ba7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983c5726-ce91-4651-9832-7ec922c2c79a",
   "metadata": {},
   "source": [
    "Ahora obtenemos el api-key de la siguiente manera, de tal forma que como puede verse es totalmente trasparente para el usuario final. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b03ec523-8597-41a9-92a4-def91b5ea447",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('claves/clave_openai.txt')\n",
    "api_key = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "865a216d-e1af-45c6-be7f-cd82300a7e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora ya nos podemos conectar a OpenAI\n",
    "llm = ChatOpenAI(openai_api_key=api_key, model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    max_tokens=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bd7f0b-ec88-4161-9d80-e8d8a11536d3",
   "metadata": {},
   "source": [
    "Los diferentes modelos los podemos ver en este enlace:\n",
    "\n",
    "https://platform.openai.com/settings/organization/limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3af9da26-ef02-48f0-8048-091dfc9deee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'adore la programmation.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 31, 'total_tokens': 37, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_ff092ab25e', 'finish_reason': 'stop', 'logprobs': None}, id='run-297a3bf5-0c5d-4e8f-9f47-4a9e480aeb60-0', usage_metadata={'input_tokens': 31, 'output_tokens': 6, 'total_tokens': 37, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16068f3d-4d95-4c8b-876d-31fa9dc9baad",
   "metadata": {},
   "source": [
    "Listo, de esta manera ya tendremos listo el operativo con OpenAi.\n",
    "\n",
    "Tambi√©n existe en LangChain un componente que nos va a permitir saber el coste que supone una llamada cualquiera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "effb0dbe-7ba9-4bc9-811b-dc35f33c9e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 25\n",
      "\tPrompt Tokens: 20\n",
      "\t\tPrompt Tokens Cached: 0\n",
      "\tCompletion Tokens: 5\n",
      "\t\tReasoning Tokens: 0\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0001\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.callbacks import get_openai_callback\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    result = llm.invoke(\"Traduce la siguiente expresi√≥n : Hace mucho calor, al ingl√©s\")\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9b31565-2eb5-415e-8c27-9128365649bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"It's very hot.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 20, 'total_tokens': 25, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f9f4fb6dbf', 'finish_reason': 'stop', 'logprobs': None}, id='run-d7f1b390-297d-413e-ad5a-14a85afc709e-0', usage_metadata={'input_tokens': 20, 'output_tokens': 5, 'total_tokens': 25, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acac0e81-2f01-4f20-b538-8fba6046d705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's very hot.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e673ab-b54b-4aba-b195-d672c6663b4c",
   "metadata": {},
   "source": [
    "## DeepSeek\n",
    "\n",
    "Para ver las ventajas que ofrece este LLM, se puede ver el v√≠deo que se indica en el siguiente enlace:\n",
    "\n",
    "https://www.youtube.com/watch?v=0wrrMkXQnYk\n",
    "\n",
    "Deepseek utiliza el SDK de openai lo que hace f√°cil y familiar desarrollar proyectos de inteligencia artificial. Como en el caso que hemos visto en el apartado anterior, tambi√©n para el uso de esta herramienta se necesita tener una api-key y tener un saldo en al cuenta de Deepsek.\n",
    "\n",
    "A continuaci√≥n se muestra un ejemplo de c√≥mo poder entrar y utilizar esa LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f70f158-11f0-4577-bc6a-ab3ca2802402",
   "metadata": {},
   "outputs": [],
   "source": [
    "#leenos la clave de un ficehro externo para as√≠ no exponerla en el c√≥digp\n",
    "f2 = open('claves/clave_deepseek.txt')\n",
    "api_key2 = f2.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff519071-92d9-46e1-a958-af69ea8677a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬°Buenos d√≠as! üòä ¬øEn qu√© puedo ayudarte hoy? ¬øTienes alguna pregunta interesante en mente o algo en lo que necesites asistencia?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=api_key2, base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Eres un asitente sobre ciertas preguntas interesantes\"},\n",
    "        {\"role\": \"user\", \"content\": \"Bueos d√≠as\"},\n",
    "    ],\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190d6aca-f379-40bf-a998-a9f72a5e9a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
