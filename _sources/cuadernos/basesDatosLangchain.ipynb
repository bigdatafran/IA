{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34879029-c6bf-429a-a12f-cb3f8de4cecd",
   "metadata": {},
   "source": [
    "# Bases de datos en LangChain.\n",
    "\n",
    "En este apartado vamos a ver los siguientes aspectos:\n",
    "\n",
    "* ¿Cómo cargar fuentes de datos de todo tipo con Langchain\n",
    "\n",
    "* ¿Cómo transformar documentos y fragmentarlos?\n",
    "\n",
    "* ¿Cómo convertir documentos en vectores a partir de incrustaciones embeddings\n",
    "\n",
    "* ¿Cómo almacenar los datos (internos y externos) en una base de datos vectorizada?\n",
    "\n",
    "* ¿Cómo realizar consultas a la base de datos vectorizada y mejorar los resultados con LLMs\n",
    "\n",
    "Comenzamos con el primer apartado, es decír, cómo poder cargar datos de múltiples fuentes.\n",
    "\n",
    "## Cargadores de documentos.\n",
    "\n",
    "Langchain viene con herramientas de carga integradas para cargar rápidamente archivos en su propio objeto Documento.\n",
    "\n",
    "Muchos de estos cargadores requieren otras bibliotecas, por ejemplo, la carga de PDF requiere la biblioteca pypdf y la carga de HTML requiere la biblioteca Beautiful Soup . Asegurar de instalar las bibliotecas requeridas antes de usar el cargador (los cargadores informarán si no pueden encontrar las bibliotecas instaladas).\n",
    "\n",
    "Entre otras librerias es muy conveniente tener instalada la  librería *Langchain community* para loaders en Python .\n",
    "\n",
    "Para ver la documentación sobre los loaders de LangChain, se puede visitar el siguiente enlace: \n",
    "\n",
    "https://python.langchain.com/v0.2/docs/integrations/document_loaders/\n",
    "\n",
    "Procedemos a cargar las librerías e instanciar el modelo de tipo de chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44542e4a-c2cb-4c1d-984f-5acbfa5d9a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, SystemMessagePromptTemplate,ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=\"llama3.2\",\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', # required, but unused,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e113f93b-1f96-49e4-920d-e0e792cec1b2",
   "metadata": {},
   "source": [
    "## Cargar documentos de tipo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87a9d2e0-1d6a-4483-b407-77744b5e7984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader #pip install langchain-community en una terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6265a2fb-7cfb-4875-9641-80829442dc37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'Fuentes datos/datos_ventas_small.csv', 'row': 0}, page_content='ï»¿ID: 10145\\nCantidad: 45\\nPrecio unitario: 83,26\\nVenta total: 3746,7\\nFecha compra: 25/08/2023\\nEstado: Shipped\\nLÃ\\xadnea Producto: Motorcycles\\nCÃ³digo Producto: S10_1678\\nNombre cliente: Toys4GrownUps,com\\nCiudad: Pasadena\\nPaÃ\\xads: USA\\nTerritorio: NA\\nTamaÃ±o pedido: Medium')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cargamos el fichero CSV\n",
    "loader = CSVLoader('Fuentes datos/datos_ventas_small.csv',csv_args={'delimiter': ';'})\n",
    "#Creamos el objeto \"data\" con los datos desde el cargador \"loader\"\n",
    "data = loader.load()\n",
    "#print(data) #Vemos que se ha creado un documento por cada fila donde el campo page_content contiene los datos\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c35507a5-2eeb-41eb-bbea-5223d7142bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿ID: 10159\n",
      "Cantidad: 0\n",
      "Precio unitario: 100\n",
      "Venta total: 0\n",
      "Fecha compra: 10/10/2023\n",
      "Estado: Shipped\n",
      "LÃ­nea Producto: Motorcycles\n",
      "CÃ³digo Producto: S10_1678\n",
      "Nombre cliente: Corporate Gift Ideas Co,\n",
      "Ciudad: San Francisco\n",
      "PaÃ­s: USA\n",
      "Territorio: NA\n",
      "TamaÃ±o pedido: Medium\n"
     ]
    }
   ],
   "source": [
    "print(data[1].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0b205b-2d46-49d1-991d-cb69f2f114f8",
   "metadata": {},
   "source": [
    "## Cargar datos HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e403a627-7a4f-4af4-a103-92b2bc55beaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import BSHTMLLoader #pip install beautifulsoup4 en una terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81a13c1b-101a-49f8-b2a1-6a213aae86ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Fuentes datos/ejemplo_web.html', 'title': ''}, page_content='\\n\\n\\n\\n\\nSQL, Structure Query Language (Lenguaje de Consulta Estructurado) es un lenguaje de\\nprogramacion para trabajar con base de datos relacionales como MySQL, Oracle, etc.\\nMySQL es un interpretador de SQL, es un servidor de base de datos.\\nMySQL permite crear base de datos y tablas, insertar datos, modificarlos, eliminarlos,\\nordenarlos, hacer consultas y realizar muchas operaciones, etc., resumiendo: administrar bases\\nde datos.\\n\\n\\nEste tutorial tiene por objetivo acercar los conceptos iniciales para introducirse en el mundo de\\nlas bases de datos.\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = BSHTMLLoader('Fuentes datos/ejemplo_web.html')\n",
    "data = loader.load()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "014e0969-e655-4e84-b7e3-c7452668ca1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SQL, Structure Query Language (Lenguaje de Consulta Estructurado) es un lenguaje de\n",
      "programacion para trabajar con base de datos relacionales como MySQL, Oracle, etc.\n",
      "MySQL es un interpretador de SQL, es un servidor de base de datos.\n",
      "MySQL permite crear base de datos y tablas, insertar datos, modificarlos, eliminarlos,\n",
      "ordenarlos, hacer consultas y realizar muchas operaciones, etc., resumiendo: administrar bases\n",
      "de datos.\n",
      "\n",
      "\n",
      "Este tutorial tiene por objetivo acercar los conceptos iniciales para introducirse en el mundo de\n",
      "las bases de datos.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b80b1da-5ded-4cff-b426-e88fef43d346",
   "metadata": {},
   "source": [
    "## Cargar datos PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1ada8d2-1437-4429-9aa8-3c6f6d764a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader #pip install pypdf en una terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b542c90e-7053-499a-bbb7-1233ba885bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyPDFLoader('Fuentes datos/Documento tecnologías emergentes.pdf')\n",
    "pages = loader.load_and_split()\n",
    "type(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e03e7b54-686c-4cf2-bf90-feaae2be6a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Microsoft® Word 2016', 'creator': 'Microsoft® Word 2016', 'creationdate': '2021-01-16T17:12:17+01:00', 'author': 'Ivan Pinar', 'moddate': '2021-01-16T17:12:17+01:00', 'source': 'Fuentes datos/Documento tecnologías emergentes.pdf', 'total_pages': 4, 'page': 0, 'page_label': '1'}, page_content='Estas son las 9 tecnologías \\nemergentes para el próximo \\n2025  \\n  \\n“Que la tecnología ha cambiado nuestra manera de vivir e interactuar \\nes un hecho. Sin embargo, aún no somos conscientes de las \\npotencialidades de usos de las tecnologías.Por  ejemplo, para el año \\n2025 se espera una verdadera revolución tecnológica, sobre todo \\nenfocado en el  sector bio -médico  pero también en las relaciones \\nhumanas entre individuos a distancia, en la protección del medio \\nambiente o en la protección de nuestros d atos personales ”, afirma \\nJuan Quintanilla, director general de Syntonize.  \\n9 Tecnologías emergentes según  Syntonize  \\nLa aplicación de nuevas tecnologías que hagan más fácil la vida a \\nprofesionales, estudiantes, mayores, empresas o instituciones \\npúblicas se e spera que aumente en los próximos años. Entre ellas se \\nencuentran;  \\n\\uf0b7 Producción optimizada por la Inteligencia Artificial:  las \\nempresas están adoptando rápidamente tecnologías basadas \\nen la nube. Gracias a ello, podrán agregar, transformar de \\nmanera intelige nte y presentar contextualmente datos de \\nproductos y procesos de las líneas de fabricación. Para 2025, \\neste flujo ubicuo de datos y los algoritmos \\ninteligentes  permitirán que las líneas de fabricación se')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7aa4cc0a-f522-4c8d-8039-b5fc838ee846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estas son las 9 tecnologías \n",
      "emergentes para el próximo \n",
      "2025  \n",
      "  \n",
      "“Que la tecnología ha cambiado nuestra manera de vivir e interactuar \n",
      "es un hecho. Sin embargo, aún no somos conscientes de las \n",
      "potencialidades de usos de las tecnologías.Por  ejemplo, para el año \n",
      "2025 se espera una verdadera revolución tecnológica, sobre todo \n",
      "enfocado en el  sector bio -médico  pero también en las relaciones \n",
      "humanas entre individuos a distancia, en la protección del medio \n",
      "ambiente o en la protección de nuestros d atos personales ”, afirma \n",
      "Juan Quintanilla, director general de Syntonize.  \n",
      "9 Tecnologías emergentes según  Syntonize  \n",
      "La aplicación de nuevas tecnologías que hagan más fácil la vida a \n",
      "profesionales, estudiantes, mayores, empresas o instituciones \n",
      "públicas se e spera que aumente en los próximos años. Entre ellas se \n",
      "encuentran;  \n",
      " Producción optimizada por la Inteligencia Artificial:  las \n",
      "empresas están adoptando rápidamente tecnologías basadas \n",
      "en la nube. Gracias a ello, podrán agregar, transformar de \n",
      "manera intelige nte y presentar contextualmente datos de \n",
      "productos y procesos de las líneas de fabricación. Para 2025, \n",
      "este flujo ubicuo de datos y los algoritmos \n",
      "inteligentes  permitirán que las líneas de fabricación se\n"
     ]
    }
   ],
   "source": [
    "print(pages[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cecd4ee-c6ab-4e3e-99bb-8f8836f99c05",
   "metadata": {},
   "source": [
    "## Caso de uso resumir un documento\n",
    "\n",
    "En este apartado vamos a ver un ejemplo concreto sobre como poder utilizar el poder la IA para hacer un resumen de un texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1771274-f7b5-4379-9396-82ae363dcd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Estas son las 9 tecnologías \\nemergentes para el próximo \\n2025  \\n  \\n“Que la tecnología ha cambiado nuestra manera de vivir e interactuar \\nes un hecho. Sin embargo, aún no somos conscientes de las \\npotencialidades de usos de las tecnologías.Por  ejemplo, para el año \\n2025 se espera una verdadera revolución tecnológica, sobre todo \\nenfocado en el  sector bio -médico  pero también en las relaciones \\nhumanas entre individuos a distancia, en la protección del medio \\nambiente o en la protección de nuestros d atos personales ”, afirma \\nJuan Quintanilla, director general de Syntonize.  \\n9 Tecnologías emergentes según  Syntonize  \\nLa aplicación de nuevas tecnologías que hagan más fácil la vida a \\nprofesionales, estudiantes, mayores, empresas o instituciones \\npúblicas se e spera que aumente en los próximos años. Entre ellas se \\nencuentran;  \\n\\uf0b7 Producción optimizada por la Inteligencia Artificial:  las \\nempresas están adoptando rápidamente tecnologías basadas \\nen la nube. Gracias a ello, podrán agregar, transformar de \\nmanera intelige nte y presentar contextualmente datos de \\nproductos y procesos de las líneas de fabricación. Para 2025, \\neste flujo ubicuo de datos y los algoritmos \\ninteligentes  permitirán que las líneas de fabricación se'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contenido_pdf=pages[0].page_content\n",
    "contenido_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d0acc9f-fda1-4eae-96c2-f429d92c6760",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = '\"Necesito que hagas un resumen del siguiente texto: \\n{contenido}\"'\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07c36a0c-1d89-48cc-a550-62ad8648841a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='\"Necesito que hagas un resumen del siguiente texto: \\nEstas son las 9 tecnologías \\nemergentes para el próximo \\n2025  \\n  \\n“Que la tecnología ha cambiado nuestra manera de vivir e interactuar \\nes un hecho. Sin embargo, aún no somos conscientes de las \\npotencialidades de usos de las tecnologías.Por  ejemplo, para el año \\n2025 se espera una verdadera revolución tecnológica, sobre todo \\nenfocado en el  sector bio -médico  pero también en las relaciones \\nhumanas entre individuos a distancia, en la protección del medio \\nambiente o en la protección de nuestros d atos personales ”, afirma \\nJuan Quintanilla, director general de Syntonize.  \\n9 Tecnologías emergentes según  Syntonize  \\nLa aplicación de nuevas tecnologías que hagan más fácil la vida a \\nprofesionales, estudiantes, mayores, empresas o instituciones \\npúblicas se e spera que aumente en los próximos años. Entre ellas se \\nencuentran;  \\n\\uf0b7 Producción optimizada por la Inteligencia Artificial:  las \\nempresas están adoptando rápidamente tecnologías basadas \\nen la nube. Gracias a ello, podrán agregar, transformar de \\nmanera intelige nte y presentar contextualmente datos de \\nproductos y procesos de las líneas de fabricación. Para 2025, \\neste flujo ubicuo de datos y los algoritmos \\ninteligentes  permitirán que las líneas de fabricación se\"', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([human_prompt])\n",
    "\n",
    "chat_prompt.format_prompt(contenido=contenido_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09fe8b4d-ed7e-4441-b35e-150f5fe137ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Estás leyendo un artículo sobre las 9 tecnologías emergentes esperadas para el año 2025 según Juan Quintanilla, director general de Syntonize. A continuación, te presento un resumen del texto:\\n\\nSegún Juan Quintanilla, la tecnología está cambiando nuestra forma de vida y interactuar con otros, pero ainda no estamos conscientes de las posibles aplicaciones y usos de estas tecnologías.\\n\\nEn cuanto a las 9 tecnologías emergentes esperadas para 2025, se incluyen:\\n\\n1. Producción optimizada por la Inteligencia Artificial\\n2. Tecnologías basadas en la nube (donde se agrega valor al flujo de datos y los algoritmos inteligentes)\\n3. Otro punto no se menciona en esta parte del texto.\\n\\nNo se proporciona una lista completa de las 9 tecnologías, ya que solo se mencionan dos en el texto fornecido: la producción optimizada por la Inteligencia Artificial y la aplicación de la nube.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solicitud_completa = chat_prompt.format_prompt(contenido=contenido_pdf).to_messages()\n",
    "result = chat.invoke(solicitud_completa)\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "023a4b00-16bd-48ac-ae72-96da318d44b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estas son las 9 tecnologías \n",
      "emergentes para el próximo \n",
      "2025  \n",
      "  \n",
      "“Que la tecnología ha cambiado nuestra manera de vivir e interactuar \n",
      "es un hecho. Sin embargo, aún no somos conscientes de las \n",
      "potencialidades de usos de las tecnologías.Por  ejemplo, para el año \n",
      "2025 se espera una verdadera revolución tecnológica, sobre todo \n",
      "enfocado en el  sector bio -médico  pero también en las relaciones \n",
      "humanas entre individuos a distancia, en la protección del medio \n",
      "ambiente o en la protección de nuestros d atos personales ”, afirma \n",
      "Juan Quintanilla, director general de Syntonize.  \n",
      "9 Tecnologías emergentes según  Syntonize  \n",
      "La aplicación de nuevas tecnologías que hagan más fácil la vida a \n",
      "profesionales, estudiantes, mayores, empresas o instituciones \n",
      "públicas se e spera que aumente en los próximos años. Entre ellas se \n",
      "encuentran;  \n",
      " Producción optimizada por la Inteligencia Artificial:  las \n",
      "empresas están adoptando rápidamente tecnologías basadas \n",
      "en la nube. Gracias a ello, podrán agregar, transformar de \n",
      "manera intelige nte y presentar contextualmente datos de \n",
      "productos y procesos de las líneas de fabricación. Para 2025, \n",
      "este flujo ubicuo de datos y los algoritmos \n",
      "inteligentes  permitirán que las líneas de fabricación seoptimicen continuamente. Así se podrá reducir el de sperdicio \n",
      "total en la fabricación hasta en un 50% . Como resultado, \n",
      "disfrutaremos de productos de mayor calidad, producidos \n",
      "más rápido y a menor coste para nuestros bolsillos y el \n",
      "medio ambiente.  \n",
      " Energías renovables de largo alcance:  en 2025, la huella \n",
      "de carbono se considerará socialmente inaceptable. La \n",
      "pandemia ha centrado la atención en la necesidad de tomar \n",
      "medidas para las amenazas a nuestra forma de vida, nuestra \n",
      "salud y nuestro futuro. Por ello, las personas, las empresas y \n",
      "los países buscarán las fo rmas más rápidas y asequibles para \n",
      "lograr cero neto de emisiones. Además, surgirá una industria \n",
      "masiva de gestión del carbono para capturar, utilizar y \n",
      "eliminar el dióxido de carbono,  desencadenando una ola de \n",
      "innovación comparable con las revoluciones ind ustriales y \n",
      "digitales del pasado.  \n",
      " Los ordenadores cuánticos:  aterrizarán oficialmente en el \n",
      "mercado, a través de ellos podremos abordar problemas \n",
      "muchos más complejos, como reacciones químicas \n",
      "complejas, que facilitarán la investigación y la aplicación \n",
      "médica. Los cálculos cuánticos ayudaran al diseño de \n",
      "materiales con propiedades nunca antes pensadas.  \n",
      " Prevención sanitaria a través de la comida:  los sistemas \n",
      "de atención médica adoptarán en 2025 enfoques de salud \n",
      "más preventivos basados, principalmente, en la ciencia \n",
      "detrás de los beneficios para la salud de las dietas ricas en \n",
      "nutrientes vegetales. Esta tendencia estará habilitada por \n",
      "tecnologías basadas en IA mediante la biología de sistemas.La aplicación de nuevas tecnologías \n",
      "que hagan más fácil la vida a \n",
      "profesionales, estudiantes, mayores, \n",
      "empresas o instituciones públicas se \n",
      "espera que aumente en los próximos \n",
      "años  \n",
      " El 5G mejorará la economía global y salvará vidas:  el \n",
      "confinamiento ha provocado un crecimiento muy importante \n",
      "en el uso de la videoconferencia por parte de empresas y \n",
      "centros educativos, especialmente a través de redes de baja \n",
      "calidad. Las redes 5G de baja latencia resolverían esta falta \n",
      "de confiabilidad de red e incluso permitirían más servicios de \n",
      "alta capacidad, como telesalud, telecirugía o servicios de \n",
      "emergencia.  \n",
      " Nueva normalidad frente al cáncer:  la tecnología impulsa \n",
      "los datos, los datos catalizan el conocimiento y el \n",
      "conocimiento permite el empode ramiento. En el futuro más \n",
      "cercano, el cáncer se manejará como cualquier afección de \n",
      "salud crónica. Podremos identificar con precisión a lo que nos \n",
      "podemos enfrentar y estar capacitados para superarlo. De la \n",
      "misma manera, viviremos una revolución en el tra tamiento \n",
      "impulsado por la tecnología.  \n",
      " Ruptura de la barrera virtual -real:  en los próximos años, \n",
      "podremos ver que este progreso se acelere, con tecnologías \n",
      "de inteligencia artificial creadas para conectar a las personas \n",
      "a nivel humano y acercarlas entre sí,  incluso cuando estánfísicamente separadas. La línea entre el espacio físico y lo \n",
      "virtual se borrará para siempre.  \n",
      " Remitir el cambio climático:  una ampliación de las \n",
      "tecnologías de emisión negativa, como la eliminación de \n",
      "dióxido de carbono, eliminará del  aire las cantidades de CO2 \n",
      "relevantes para el clima. Esto será necesario para limitar el \n",
      "calentamiento global a 1,5° C. Si bien la humanidad hará \n",
      "todo lo posible por dejar de emitir más carbono a la \n",
      "atmósfera, también hará todo lo posible para eliminar el  CO2 \n",
      "histórico del aire de forma permanente.  \n",
      " Comprender los secretos microscópicos ocultos en las \n",
      "superficies:  la tecnología que acelera nuestra capacidad de \n",
      "muestrear, digitalizar e interpretar rápidamente los datos de \n",
      "los microbiomas transformará nuestra  comprensión de cómo \n",
      "se propagan los patógenos.  \n",
      " La privacidad estará generalizada y priorizada:  la \n",
      "capacidad de los consumidores para proteger y controlar los \n",
      "activos de datos confidenciales se considerará como la regla \n",
      "y no como la excepción. Las tecnolog ías de mejora de la \n",
      "privacidad supondrán una categoría tecnológica propia y se \n",
      "convertirán en un elemento fundamental de las estrategias \n",
      "de privacidad y seguridad de la empresa.\n"
     ]
    }
   ],
   "source": [
    "#Resumir el documento completo\n",
    "#Creamos una string concatenando el contenido de todas las páginas\n",
    "documento_completo = \"\"\n",
    "for page in pages:\n",
    "    documento_completo += page.page_content  # Supongamos que cada página tiene un atributo 'text'\n",
    "\n",
    "print(documento_completo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7becc472-d7b3-4dbd-b7fd-ad1b25ea5af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "solicitud_completa = chat_prompt.format_prompt(contenido=documento_completo).to_messages()\n",
    "result = chat.invoke(solicitud_completa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afe79dec-50a8-483a-8c84-3d5b65b3df34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A continuación, te presento un resumen del texto sobre 9 tecnologías emergentes para el año 2025:\\n\\n1. **Producción optimizada por la Inteligencia Artificial**: la implementación de tecnologías basadas en IA permitirá agregar valor a datos de productos y procesos de las líneas de fabricación, reduciendo el desperdicio total en la fabricación hasta un 50%.\\n\\n2. **Energías renovables de largo alcance**: se espera que la huella de carbono sea socialmente inaceptable en 2025, lo que impulsará una industria masiva para gestionar el carbono y capturar, utilizar y eliminar el dióxido de carbono.\\n\\n3. **Ordenadores cuánticos**: estos ordenadores podrán abordar problemas complejos como reacciones químicas y facilitar la investigación y la aplicación médica.\\n\\n4. **Prevención sanitaria a través de la comida**: se espera que los sistemas de atención médica adopten enfoques de salud más preventivos basados en la ciencia detrás de los beneficios para la salud de las dietas ricas en nutrientes vegetales.\\n\\n5. **El 5G mejorará la economía global y salvará vidas**: el 5G resolverá la falta de confiabilidad de red e incluso permitirá servicios de alta capacidad, como telesalud, telecirugía o servicios de emergencia.\\n\\n6. **Nueva normalidad frente al cáncer**: la tecnología impulsa el conocimiento que permite el empoderamiento y se manejará el cáncer como cualquier afección de salud crónica.\\n\\n7. **Ruptura de la barrera virtual -real**: las tecnologías de inteligencia artificial acelerarán la conexión entre personas e incluso entre aquellos físicamente separados, borrando la línea entre el espacio físico y lo virtual.\\n\\n8. **Remitir el cambio climático**: se espera que las tecnologías de emisión negativa eliminan del aire las cantidades de CO2 relevantes para el clima.\\n\\n9. **Comprender los secretos microscópicos ocultos en las superficies**: la tecnología acelerará nuestra capacidad de muestrer, digitalizar e interpretar rápidamente los datos de los microbiomas transformando nuestra comprensión de cómo se propagan los patógenos.\\n\\nEn general, estas 9 tecnologías tendrá un impacto significativo en el futuro de la humanidad, desde mejorar nuestros bienes y servicios hasta reducir posibles daños climáticos.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957f8fb7-2250-47e0-80f5-34d504919261",
   "metadata": {},
   "source": [
    "## Integración con otras plataformas.\n",
    "\n",
    "Existen otros cargadores de documentos que son denominados \"integraciones\" y pueden ser considerados esencialmente lo mismo que los cargadores normales vistos en la sección anterior, pero con la salvedad y la ventaja de que están integrados con otras plataformas como por ejemplo:\n",
    "\n",
    "* Plataforma de terceros (como Google Cloud, AWS, Google Drive, Dropbox,…)\n",
    "\n",
    "* Base de datos (como MongoDB)\n",
    "\n",
    "* Sitio web específico, como Wikipedia\n",
    "\n",
    "* Permiten cargar vídeos de Youtube (por ejemplo, crear una aplicación de preguntas y respuestas en base a vídeos de Youtube ), conversaciones de WhatsApp y un sinfín de posibilidades.\n",
    "\n",
    "Con todas estas integraciones, vamos a tener la ventaja de cargar esta información en una base de datos vectorial y después consultar esa información con todas las ventajas que esta información nos puede proporcionar.\n",
    "\n",
    "\n",
    "La documentación sobre este tipo de cargadores (document loaders - integraciones), se tiene en este enlace: \n",
    "\n",
    "https://python.langchain.com/v0.2/docs/integrations/document_loaders/\n",
    "\n",
    "### Cargar informaciones de wikipedia.\n",
    "\n",
    "A continuación vamos a mostrar un caso de usos que consiste en cargar información de la wikipedia. Como siempre cargamos los paquetes correspondientes y cargamos el chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86debae2-3ec7-4a85-94bf-5ee29f6dbf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, SystemMessagePromptTemplate,ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=\"llama3.2\",\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', # required, but unused,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ded7b1ee-98c1-41c3-aeab-b79413a2489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef4b997e-253f-4e66-ace8-ebfcff32054b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WikipediaLoader # pip install wikipedia en una terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2167829-166d-4d97-b8de-913674c3d696",
   "metadata": {},
   "source": [
    "Definimos la siguiente función que es la que nos va a servir para obtener y ejecutar lo que necesitamos para hacer consultas apoyadas en la información que figura en la wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5d52dbe-3899-46e8-a398-634c95fa1dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def responder_wikipedia(persona,pregunta_arg):\n",
    "    # Obtener artículo de wikipedia\n",
    "    docs = WikipediaLoader(query=persona,lang=\"es\",load_max_docs=10) #parámetros posibles en: https://python.langchain.com/v0.2/docs/integrations/document_loaders/wikipedia/\n",
    "    # Observar que el valor de \"persona\" lo pasamos como parámetro a la función\n",
    "    contexto_extra = docs.load()[0].page_content #para que sea más rápido solo pásamos el primer documento [0] como contexto extra\n",
    "    \n",
    "    # Pregunta de usuario, que se la pasamos como parámetro de la función\n",
    "    human_prompt = HumanMessagePromptTemplate.from_template('Responde a esta pregunta\\n{pregunta}, aquí tienes contenido extra:\\n{contenido}')\n",
    "    \n",
    "    # Construir prompt\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([human_prompt])\n",
    "    \n",
    "    # Resultado\n",
    "    result = chat.invoke(chat_prompt.format_prompt(pregunta=pregunta_arg,contenido=contexto_extra).to_messages())\n",
    "    \n",
    "    print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b881125e-adac-4818-8c85-42e237db731a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Según la información proporcionada, José María Aznar López nació en Madrid, España.\n"
     ]
    }
   ],
   "source": [
    "responder_wikipedia(\"José María Aznar\",\"¿En qué localidad nació?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d7ffc2-60d4-49b9-a21d-9e71ac6e68ad",
   "metadata": {},
   "source": [
    "## Transformación de documentos.\n",
    "```{index} transformadores de documentos, chunks\n",
    "```\n",
    "\n",
    "Hay que tener en cuenta que después de cargar un objeto Documento desde una fuente, terminará con cadenas de texto desde el campo page_content. Entonces puede haber situaciones en las que la longitud de las cadenas asó obtenidas pueden ser muy grandes  para alimentar un modelo (por ejemplo, límite de 8k tokens ~6k palabras). Para resolver este problema, Langchain proporciona **transformadores de documentos** que permiten dividir fácilmente cadenas del page_content en fragmentos (que se conocen como chunks).\n",
    "\n",
    "Estos fragmentos servirán más adelante además como componentes útiles en forma de vectores a partir de una incrustación (embeddings ), que luego podremos buscar utilizando una similitud de distancia más adelante. Por ejemplo, si queremos alimentar un LLM con contexto adicional para que sirva como chatbot de preguntas y respuestas, si tenemos varios vectores guardados cada uno con una información diferente, la búsqueda será más rápida puesto que se hará un cálculo del vector guardado que tiene mayor similaridad en lugar de buscar en todos los datos globales.\n",
    "\n",
    "Veamos ahora un ejemplo ilustrativo de cómo poder hacer todo esto. Para hacer esto vamos a cargar un documento bastante extenso y con mucha información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a3fd289-2343-48ef-8192-aeddea8533f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85369"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Fuentes datos/Historia España.txt', encoding=\"utf8\") as file:\n",
    "    texto_completo = file.read()\n",
    "\n",
    "# Números de caracteres\n",
    "len(texto_completo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0a1369-b93e-4ba3-a2c9-c1427778c52b",
   "metadata": {},
   "source": [
    "Como podemos ver es un documento bastante extenso y lo que vamos a hacer es dividirlo en trozos más pequeños, los cuales tienen la denominación de chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa955283-9a6e-4b01-a015-9cc1fe483fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51663b01-7f8d-4406-9c26-67118d6d8b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(separator=\"\\n\",chunk_size=1000) #Indicamos que divida cuando se encuentra 1 salto de línea y trate de hacer fragmentos de 1000 caracteres\n",
    "# Intenta hacer los chunks más o menos del tamaño que se le da, en este caso de 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f353f3-a50e-4443-8e51-f87f91a49131",
   "metadata": {},
   "source": [
    "Existen muchas más posibilidades para hacer esto, las cuales se pueden ver en este enlace: \n",
    "https://python.langchain.com/api_reference/text_splitters/character/langchain_text_splitters.character.CharacterTextSplitter.html\n",
    "\n",
    "Entre estas posibilidaddes está una muy utilizada y es que los cuhunks puedan tener cierto solpamientos, es decir que las últimas palabras del chunk anterior, sean también las palabras del chunk siguiente. Este efecto lo conseguimos con la opción *chunk_overlap*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b38ca7ea-605d-4917-bc71-410314da87a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1424, which is longer than the specified 1000\n",
      "Created a chunk of size 1290, which is longer than the specified 1000\n",
      "Created a chunk of size 1191, which is longer than the specified 1000\n",
      "Created a chunk of size 1232, which is longer than the specified 1000\n",
      "Created a chunk of size 1193, which is longer than the specified 1000\n",
      "Created a chunk of size 1053, which is longer than the specified 1000\n",
      "Created a chunk of size 1248, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "texts = text_splitter.create_documents([texto_completo]) #Creamos documentos gracias al transformador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e5d99f2-35ee-4c57-a9c1-e1b672308ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "\n",
      "\n",
      "<class 'langchain_core.documents.base.Document'>\n",
      "\n",
      "\n",
      "page_content='Los primeros homínidos llegaron al territorio de la actual España hace 1,2 millones de años aproximadamente. Se sucedieron varias especies, como Homo antecessor, los preneandertales de la Sima de los Huesos (identificados en un principio como Homo heidelbergensis) y los neandertales (Homo neanderthalensis), hasta que hace unos 35 000 años los humanos modernos (Homo sapiens) entraron en la península ibérica y fueron desplazando a estos últimos, con los que aún coexistirían durante cerca de 10 000 años. Hace unos 27 000 años se extinguieron las últimas poblaciones neandertales en el sur. Durante los milenios siguientes el territorio fue lugar del asentamiento de pueblos íberos, celtas, fenicios, cartagineses, tartessos y griegos y hacia el 200 a. C. la península comenzó a formar parte de la República romana, constituyendo la Hispania romana. Tras la caída de Roma, se estableció el reino visigodo. Dicha monarquía visigótica se inició en el siglo v y se mantuvo hasta comienzos del siglo viii. En el año 711 se produjo la primera conquista musulmana desde el Norte de África en pocos años el islam dominaba gran parte de la península ibérica. Durante los 750 años siguientes, el reino dominado por musulmanes sería conocido como al-Ándalus, y mientras que gran parte del resto de Europa permanecía en los años oscuros, Al-Ándalus experimentaba un esplendoroso florecimiento multicultural, científico y artístico.1​'\n"
     ]
    }
   ],
   "source": [
    "print(type(texts)) #Verificamos el tipo del objeto obtenido\n",
    "print('\\n')\n",
    "print(type(texts[0])) #Verificamos el tipo de cada elemento\n",
    "print('\\n')\n",
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f65293d-9424-41b2-8efc-8b6e24c53639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1424"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19155f35-6e55-4706-bf7b-3c759d63ff8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content='De modo paulatino, se produjo la Reconquista, y los reinos cristianos arrebataron progresivamente el territorio a los musulmanes. Comenzada aproximadamente en 722 con la rebelión de Don Pelayo y partiendo desde el norte, avanzó durante los siglos viii a xv culminando con la conquista de Granada en 1492. Durante este periodo los reinos cristianos se desarrollaron notablemente; la unión de los dos más importantes, Castilla y Aragón, por el matrimonio en 1469 de los Reyes Católicos, Isabel I de Castilla y Fernando II de Aragón, posibilitaría la unificación de España y el fin de la Reconquista.2\\u200b3\\u200b4\\u200b5\\u200b')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8b4f1d1-e311-4a32-ba27-1042ed589d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1424\n",
      "605\n",
      "581\n",
      "589\n",
      "688\n",
      "696\n",
      "978\n",
      "832\n",
      "836\n",
      "889\n",
      "914\n",
      "687\n",
      "647\n",
      "863\n",
      "811\n",
      "783\n",
      "951\n",
      "957\n",
      "355\n",
      "978\n",
      "687\n",
      "809\n",
      "380\n",
      "965\n",
      "977\n",
      "670\n",
      "692\n",
      "734\n",
      "620\n",
      "878\n",
      "1290\n",
      "653\n",
      "976\n",
      "910\n",
      "919\n",
      "577\n",
      "758\n",
      "588\n",
      "473\n",
      "940\n",
      "850\n",
      "857\n",
      "272\n",
      "1191\n",
      "758\n",
      "1232\n",
      "985\n",
      "949\n",
      "1193\n",
      "915\n",
      "453\n",
      "903\n",
      "1000\n",
      "822\n",
      "664\n",
      "984\n",
      "471\n",
      "562\n",
      "801\n",
      "697\n",
      "572\n",
      "824\n",
      "985\n",
      "933\n",
      "558\n",
      "977\n",
      "927\n",
      "993\n",
      "864\n",
      "811\n",
      "949\n",
      "768\n",
      "486\n",
      "995\n",
      "1053\n",
      "812\n",
      "972\n",
      "943\n",
      "983\n",
      "969\n",
      "975\n",
      "955\n",
      "386\n",
      "1248\n",
      "658\n",
      "924\n",
      "875\n",
      "951\n",
      "947\n",
      "979\n",
      "994\n",
      "847\n",
      "893\n",
      "661\n",
      "978\n",
      "959\n",
      "845\n",
      "823\n",
      "991\n",
      "811\n",
      "995\n",
      "918\n",
      "890\n",
      "865\n",
      "759\n",
      "878\n",
      "990\n",
      "927\n",
      "728\n"
     ]
    }
   ],
   "source": [
    "# Veamos la longitud de cada uno de los chunks que se han obtenido\n",
    "for h in texts:\n",
    "    print(len(h.page_content))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "550871e4-b15e-458b-8c4e-c113a0ddcad9",
   "metadata": {},
   "source": [
    "## Incrustación de texto y creación de vectores (embeging)\n",
    "```{index} Embeding, OllamaEmbeddings\n",
    "```\n",
    "\n",
    "**NOTA**: [En este otro apartado](embeding), también se puede ver desde diferentes puntos de vista cómo poder trabajar con este tipo embeding.\n",
    "\n",
    "De cara a trabajar con textos en IA, lo que se suele hacer es transformar esos textos en una representación de los mismos mediante una serie de vectores que contienen información semántica de esos textos. Langchain admite muchas incrustaciones de texto, que pueden convertir directamente texto en una representación vectorizada incrustada.\n",
    "\n",
    "En resumen, los modelos incrustados crean una representación vectorial de un fragmento de texto . Puedes pensar en un vector como una matriz de números que captura el significado semántico del texto. Al representar el texto de esta manera, puede realizar operaciones matemáticas que le permiten hacer cosas como buscar otras partes del texto que tengan un significado más similar.\n",
    "\n",
    "![](fig/embeding.PNG)\n",
    "\n",
    "Estos modelos de embeding que utiliza LangChain, se puede ver su explicación en el siguiente enlace:\n",
    "\n",
    "https://python.langchain.com/v0.2/docs/concepts/#embedding-models\n",
    "\n",
    "**NOTA** : Los diferentes modelos de incrustación puede que no interactúen entre sí, lo que significa que necesitaría volver a incrustar un conjunto completo de documentos si cambiara de modelo de incrustación en el futuro. En este se indicará cómo utilizar OpenAI, pues es uno de los métodos más utilizados, pero como se intenta hacer una explicación de estos métodos desde un punto de vista didáctico, sin incurrir en costes, se utilizará ollama para hacer cuestiones prácticas sobre estos métodos.\n",
    "\n",
    "Se aconseja al lector mirar estos enlaces:\n",
    "\n",
    "* <a href=\"https://python.langchain.com/docs/integrations/text_embedding/ollama/\" target=\"_blank\">Presentación de OllamaEmbeddings </a>\n",
    "\n",
    "* <a href=\"https://python.langchain.com/api_reference/ollama/embeddings/langchain_ollama.embeddings.OllamaEmbeddings.html\" target=\"_blank\">Api de OllamaEmbeddings </a>\n",
    "\n",
    "A continuación se muestra un caso práctico sobre cómo utilizar todos estos procesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "444c554f-ff6c-42a3-b685-c92273957633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, SystemMessagePromptTemplate,ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=\"llama3.2\",\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', # required, but unused,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662199ae-90a6-4269-a28a-33a80b1f2f91",
   "metadata": {},
   "source": [
    "Si quisiéramos hacer esto desde OpenAi, el código a utilizar sería el siguiente: (Se ha dejado comentado el código)\n",
    "\n",
    "**NOTA**: Para ver cómo empezar con OpenAi, se recomienda ver [este apartado](pago) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16be6a33-18f5-4837-9f62-03716c440f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain_openai import OpenAIEmbeddings\n",
    "# embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "# texto = \"Esto es un texto enviado a OpenAI para ser incrustado en un vector n-dimensional\"\n",
    "#embedded_text = embeddings.embed_query(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7503a4-a854-445d-8acb-d2a0b2828ca1",
   "metadata": {},
   "source": [
    "Sin embargo y con el fin de evitar costes, vamos a ver cómo haríamos estos embeding, utilizando ollama desde LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0310837e-9f9b-466b-a948-f5475aad3563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76bf4143-413d-4996-acbf-813f37cf10ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"llama3.2\",\n",
    ")\n",
    "\n",
    "texto = \"Este es el texto que vamos a vectorizar utilizando para ello llama que sale gratuito\"\n",
    "embedded_text = embeddings.embed_query(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2e9775c-50da-4458-aa17-74758c49f545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embedded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e83b7c4-ffcb-4d07-a00c-70912b815550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.02119353,\n",
       " -0.013681516,\n",
       " 0.032055188,\n",
       " -0.005358407,\n",
       " -0.010106426,\n",
       " -0.0073281615,\n",
       " 0.010382513,\n",
       " -0.015157732,\n",
       " 0.009666262,\n",
       " -0.0072076097]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa90275c-1513-4050-90d9-fb1764a3b7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este mismo ejercicio pero de forma asíncrona\n",
    "embedded_text = await embeddings.aembed_query(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2081f443-9b5a-4ce5-8885-2246aa76fa9b",
   "metadata": {},
   "source": [
    "Si quisiéramos hacer esto con varios textos deberíamos utilizar una expresión similar a la siguiente:\n",
    "\n",
    "```\n",
    "input_texts = [\"Document 1...\", \"Document 2...\"]\n",
    "vectors = embed.embed_documents(input_texts)\n",
    "print(len(vectors))\n",
    "# The first 3 coordinates for the first vector\n",
    "print(vectors[0][:3])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6053fad-a0f8-4ae4-822d-07e0d76bc3d8",
   "metadata": {},
   "source": [
    "### Incrustación de documentos.\n",
    "\n",
    "A continuación se muestra un ejemplo, para ver cómo podemos hacer embedings de documentos, que es la situación real con la que nos encontraremos al trabajar con IA.\n",
    "\n",
    "Lo primero que hacemos es cargar un documento de tipo CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd4b56f2-4501-4438-b307-3f5747a005c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea2a0ec2-99a4-43b3-8a1a-5eb60082ca92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = CSVLoader('Fuentes datos/datos_ventas_small.csv',csv_args={'delimiter': ';'})\n",
    "data = loader.load()\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "820f28ce-9484-459f-b3ce-1c5874131547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3d2a83b-b445-4b9a-9dae-115e2d023066",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No podemos incrustar el objeto \"data\" puesto que es una lista de documentos, lo que espera es una string\n",
    "# Ejecutar el siguiente comando nos daría un error\n",
    "#embedded_docs = embeddings.embed_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf313f54-4ee1-42d1-a5ea-db5e855270f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ï»¿ID: 10145\\nCantidad: 45\\nPrecio unitario: 83,26\\nVenta total: 3746,7\\nFecha compra: 25/08/2023\\nEstado: Shipped\\nLÃ\\xadnea Producto: Motorcycles\\nCÃ³digo Producto: S10_1678\\nNombre cliente: Toys4GrownUps,com\\nCiudad: Pasadena\\nPaÃ\\xads: USA\\nTerritorio: NA\\nTamaÃ±o pedido: Medium',\n",
       " 'ï»¿ID: 10159\\nCantidad: 0\\nPrecio unitario: 100\\nVenta total: 0\\nFecha compra: 10/10/2023\\nEstado: Shipped\\nLÃ\\xadnea Producto: Motorcycles\\nCÃ³digo Producto: S10_1678\\nNombre cliente: Corporate Gift Ideas Co,\\nCiudad: San Francisco\\nPaÃ\\xads: USA\\nTerritorio: NA\\nTamaÃ±o pedido: Medium',\n",
       " 'ï»¿ID: 10168\\nCantidad: 36\\nPrecio unitario: 96,66\\nVenta total: 3479,76\\nFecha compra: 28/10/2023\\nEstado: Shipped\\nLÃ\\xadnea Producto: Motorcycles\\nCÃ³digo Producto: S10_1678\\nNombre cliente: Technics Stores Inc,\\nCiudad: Burlingame\\nPaÃ\\xads: USA\\nTerritorio: NA\\nTamaÃ±o pedido: Medium',\n",
       " 'ï»¿ID: 10180\\nCantidad: 29\\nPrecio unitario: 86,13\\nVenta total: 2497,.77\\nFecha compra: 11/11/2023\\nEstado: Shipped\\nLÃ\\xadnea Producto: Motorcycles\\nCÃ³digo Producto: S10_1678\\nNombre cliente: Daedalus Designs Imports\\nCiudad: Lille\\nPaÃ\\xads: France\\nTerritorio: EMEA\\nTamaÃ±o pedido: Small',\n",
       " 'ï»¿ID: 10188\\nCantidad: 48\\nPrecio unitario: 100\\nVenta total: 5512,32\\nFecha compra: 18/11/2023\\nEstado: Shipped\\nLÃ\\xadnea Producto: Motorcycles\\nCÃ³digo Producto: S10_1678\\nNombre cliente: Herkku Gifts\\nCiudad: Bergen\\nPaÃ\\xads: Norway\\nTerritorio: EMEA\\nTamaÃ±o pedido: Medium',\n",
       " 'ï»¿ID: 10201\\nCantidad: 22\\nPrecio unitario: 98,57\\nVenta total: 2168,54\\nFecha compra: 12/01/2023\\nEstado: Shippe\\nLÃ\\xadnea Producto: Motorcycles\\nCÃ³digo Producto: S10_1678\\nNombre cliente: Mini Wheels Co,\\nCiudad: San Francisco\\nPaÃ\\xads: USA\\nTerritorio: NA\\nTamaÃ±o pedido: Small',\n",
       " 'ï»¿ID: 10237\\nCantidad: 23\\nPrecio unitario: 100\\nVenta total: 2333,12\\nFecha compra: 04/05/2024\\nEstado: Shipped\\nLÃ\\xadnea Producto: Motorcycles\\nCÃ³digo Producto: S10_1678\\nNombre cliente: Vitachrome Inc,\\nCiudad: NYC\\nPaÃ\\xads: USA\\nTerritorio: NA\\nTamaÃ±o pedido: Small',\n",
       " 'ï»¿ID: 10251\\nCantidad: 28\\nPrecio unitario: 100\\nVenta total: 3188,64\\nFecha compra: 12/01/2023\\nEstado: Shipped\\nLÃ\\xadnea Producto: Motorcycles\\nCÃ³digo Producto: S10_1678\\nNombre cliente: Tekni Collectables Inc,\\nCiudad: Newark\\nPaÃ\\xads: USA\\nTerritorio: NA\\nTamaÃ±o pedido: Medium',\n",
       " 'ï»¿ID: 10375\\nCantidad: 42\\nPrecio unitario: 34,91\\nVenta total: 1466,22\\nFecha compra: 02/03/2024\\nEstado: Shipped\\nLÃ\\xadnea Producto: Motorcycles\\nCÃ³digo Producto: S10_1678\\nNombre cliente: La Rochelle Gifts\\nCiudad: Nantes\\nPaÃ\\xads: France\\nTerritorio: EMEA\\nTamaÃ±o pedido: Small',\n",
       " 'ï»¿ID: 10388\\nCantidad: 84\\nPrecio unitario: 76,36\\nVenta total: 6414,24\\nFecha compra: 03/03/2024\\nEstado: Shipped\\nLÃ\\xadnea Producto: Motorcycles\\nCÃ³digo Producto: S10_1678\\nNombre cliente: FunGiftIdeas,com\\nCiudad: New Bedford\\nPaÃ\\xads: USA\\nTerritorio: NA\\nTamaÃ±o pedido: Medium',\n",
       " 'ï»¿ID: 10403\\nCantidad: 48\\nPrecio unitario: 100\\nVenta total: 4869,12\\nFecha compra: 04/08/2024\\nEstado: Shipped\\nLÃ\\xadnea Producto: Motorcycles\\nCÃ³digo Producto: S10_1678\\nNombre cliente: UK Collectables, Ltd,\\nCiudad: Liverpool\\nPaÃ\\xads: UK\\nTerritorio: EMEA\\nTamaÃ±o pedido: Small',\n",
       " 'ï»¿ID: 10228\\nCantidad: 29\\nPrecio unitario: 100\\nVenta total: 6463,23\\nFecha compra: 03/10/2024\\nEstado: Shipped\\nLÃ\\xadnea Producto: Classic Cars\\nCÃ³digo Producto: S10_1949\\nNombre cliente: Cambridge Collectables Co,\\nCiudad: Cambridge\\nPaÃ\\xads: USA\\nTerritorio: NA\\nTamaÃ±o pedido: Medium',\n",
       " 'ï»¿ID: 10245\\nCantidad: 34\\nPrecio unitario: 100\\nVenta total: 6120,34\\nFecha compra: 05/04/2024\\nEstado: Shipped\\nLÃ\\xadnea Producto: Classic Cars\\nCÃ³digo Producto: S10_1949\\nNombre cliente: Super Scale Inc,\\nCiudad: New Haven\\nPaÃ\\xads: USA\\nTerritorio: NA\\nTamaÃ±o pedido: Medium',\n",
       " 'ï»¿ID: 10291\\nCantidad: 37\\nPrecio unitario: 100\\nVenta total: 7136,19\\nFecha compra: 09/08/2024\\nEstado: Shipped\\nLÃ\\xadnea Producto: Classic Cars\\nCÃ³digo Producto: S10_1949\\nNombre cliente: Scandinavian Gift Ideas\\nCiudad: Boras\\nPaÃ\\xads: Sweden\\nTerritorio: EMEA\\nTamaÃ±o pedido: Large',\n",
       " 'ï»¿ID: 10304\\nCantidad: 47\\nPrecio unitario: 100\\nVenta total: 10172,7\\nFecha compra: 10/11/2024\\nEstado: Shipped\\nLÃ\\xadnea Producto: Classic Cars\\nCÃ³digo Producto: S10_1949\\nNombre cliente: Auto Assoc, & Cie,\\nCiudad: Versailles\\nPaÃ\\xads: France\\nTerritorio: EMEA\\nTamaÃ±o pedido: Large',\n",
       " 'ï»¿ID: 10322\\nCantidad: 40\\nPrecio unitario: 100\\nVenta total: 6000,4\\nFecha compra: 11/04/2024\\nEstado: Shipped\\nLÃ\\xadnea Producto: Classic Cars\\nCÃ³digo Producto: S10_1949\\nNombre cliente: Online Diecast Creations Co,\\nCiudad: Nashua\\nPaÃ\\xads: USA\\nTerritorio: NA\\nTamaÃ±o pedido: Medium',\n",
       " 'ï»¿ID: 10391\\nCantidad: 40\\nPrecio unitario: 100\\nVenta total: 6000,4\\nFecha compra: 11/04/2024\\nEstado: Shipped\\nLÃ\\xadnea Producto: Classic Cars\\nCÃ³digo Producto: S10_1949\\nNombre cliente: Online Diecast Creations Co,\\nCiudad: Nashua\\nPaÃ\\xads: USA\\nTerritorio: NA\\nTamaÃ±o pedido: Medium',\n",
       " \"ï»¿ID: 10391\\nCantidad: 48\\nPrecio unitario: 100\\nVenta total: 4833,12\\nFecha compra: 03/09/2024\\nEstado: Shipped\\nLÃ\\xadnea Producto: Classic Cars\\nCÃ³digo Producto: S10_1949\\nNombre cliente: Anna's Decorations, Ltd\\nCiudad: North Sydney\\nPaÃ\\xads: Australia\\nTerritorio: APAC\\nTamaÃ±o pedido: Small\",\n",
       " 'ï»¿ID: 10411\\nCantidad: 46\\nPrecio unitario: 100\\nVenta total: 8280,46\\nFecha compra: 05/01/2024\\nEstado: Shipped\\nLÃ\\xadnea Producto: Classic Cars\\nCÃ³digo Producto: S10_1949\\nNombre cliente: Quebec Home Shopping Network\\nCiudad: Montreal\\nPaÃ\\xads: Canada\\nTerritorio: NA\\nTamaÃ±o pedido: Medium',\n",
       " 'ï»¿ID: 10134\\nCantidad: 27\\nPrecio unitario: 100\\nVenta total: 3307,77\\nFecha compra: 07/01/2023\\nEstado: Shipped\\nLÃ\\xadnea Producto: Motorcycles\\nCÃ³digo Producto: S10_2016\\nNombre cliente: Lyon Souveniers\\nCiudad: Paris\\nPaÃ\\xads: France\\nTerritorio: EMEA\\nTamaÃ±o pedido: Medium',\n",
       " 'ï»¿ID: 10159\\nCantidad: 37\\nPrecio unitario: 100\\nVenta total: 5016,83\\nFecha compra: 10/10/2023\\nEstado: Shipped\\nLÃ\\xadnea Producto: Motorcycles\\nCÃ³digo Producto: S10_2016\\nNombre cliente: Corporate Gift Ideas Co,\\nCiudad: San Francisco\\nPaÃ\\xads: USA\\nTerritorio: NA\\nTamaÃ±o pedido: Medium',\n",
       " 'ï»¿ID: 10159\\nCantidad: 37\\nPrecio unitario: 100\\nVenta total: 5016,83\\nFecha compra: 10/10/2023\\nEstado: Shipped\\nLÃ\\xadnea Producto: Motorcycles\\nCÃ³digo Producto: S10_2016\\nNombre cliente: Corporate Gift Ideas Co,\\nCiudad: San Francisco\\nPaÃ\\xads: USA\\nTerritorio: NA\\nTamaÃ±o pedido: Medium']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creamos una comprensión de listas concatenando el campo \"page_content\" de todos los documentos existentes en la lista \"data\"\n",
    "[elemento.page_content for elemento in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ea6d261-acfb-453f-a222-44c114e4071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_docs = embeddings.embed_documents([elemento.page_content for elemento in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa685a2f-e0d1-4c6f-baf4-c7828b4c4d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificamos cuántos vectores a creado (1 por cada registro del fichero CSV con datos)\n",
    "len(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93ff11f6-b5c8-4147-be1b-dd375c643136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.006179472,\n",
       " 0.017413776,\n",
       " 0.021690493,\n",
       " -0.0056598824,\n",
       " 0.022888422,\n",
       " -0.025513476,\n",
       " -0.002373873,\n",
       " -0.027805334,\n",
       " -0.0032582898,\n",
       " -0.0102156745]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vemos un ejemplo del vector creado para el primer registro\n",
    "embedded_docs[1][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32ca5d3-0eb4-44fd-bfcc-7b65c6153c05",
   "metadata": {},
   "source": [
    "(almacenamiento)=\n",
    "## Almacenamiento de vectores en BD.\n",
    "```{index} BD vectoriales\n",
    "```\n",
    "\n",
    "Hasta ahora hemos creado incrustaciones ( embeddings ) en memoria RAM como una lista de Python. Estos embedings en el momento en que nos salgamos de la aplicación se pierden, entonces ¿cómo podemos asegurarnos de que estas incorporaciones persistan en alguna solución de almacenamiento más permanente?\n",
    "\n",
    "Para conseguir que esta información quede almacenada para futuras consultas, utilizamos un almacén de vectores, también conocido como base de datos de vectores , sus aspectos claves:\n",
    "\n",
    "* Puede almacenar grandes vectores de N dimensiones.\n",
    "\n",
    "* Puede indexar directamente un vector incrustado y asociarlo a su documento string\n",
    "\n",
    "* Se puede \"consultar\", lo que permite una búsqueda de similitud de coseno entre un nuevo vector que no está en la base de datos y los vectores almacenados.\n",
    "  \n",
    "* Puede agregar, actualizar o eliminar fácilmente nuevos vectores.\n",
    "\n",
    "* Al igual que con los LLM y los modelos de chat, Langchain ofrece muchas opciones diferentes para almacenes de vectores.\n",
    "\n",
    "* Usaremos una base de datos de vectores open source SKLearn , pero gracias a Langchain , la sintaxis es estándar para el resto de BD.\n",
    "\n",
    "Para hacer este tipo de persistencia LangChain nos ofrece una amplia variedad de Bases de datos, las cuales las podemos consultar utilizando el siguiente link:\n",
    "\n",
    "https://python.langchain.com/v0.2/docs/integrations/vectorstores/\n",
    "\n",
    "La metodología que se emplea para este tipo de persistencia de la información, de forma esquemática se puede ver en la siguiente ilustración:\n",
    "\n",
    "![](fig/BD.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24d800c-6f31-48a1-bc9b-2ec765a12999",
   "metadata": {},
   "source": [
    "Como ya hemos hecho en casos anteriores, y con la finalidad de mostrar como actuar cuando se quiere hacer este tipo de cosas en IA, a continuación se pasa a ilustrar todo esto con algún ejemplo totalmente práctico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf4e55ee-d637-42ec-a0d5-634087ba2e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc66aeb-8081-43e4-a151-3fb0113486ac",
   "metadata": {},
   "source": [
    "Cargamos el documento y lo dividimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff053902-b536-4e68-b073-07d104fd7b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 506, which is longer than the specified 500\n",
      "Created a chunk of size 1009, which is longer than the specified 500\n",
      "Created a chunk of size 2228, which is longer than the specified 500\n"
     ]
    }
   ],
   "source": [
    "# Cargar el documento\n",
    "loader = TextLoader('Fuentes datos/Historia España.txt', encoding=\"utf8\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Dividir en chunks\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=500) #Otro método de split basándose en tokens\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79a43c0-1ade-41e8-854f-204531b9a06c",
   "metadata": {},
   "source": [
    "Procedemos a la creación de embedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebcd2d1e-a0fd-4c4e-a998-3f1e187c3ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "funcion_embedding = OllamaEmbeddings(\n",
    "    model=\"llama3.2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b294552-70f3-4b92-8618-3185df5875ba",
   "metadata": {},
   "source": [
    "Para el almacenamiento, utilizamos *SKLearn Vector Store*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3a168ee-7663-418a-84db-24c73243a4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import SKLearnVectorStore #pip install scikit-learn / pip install pandas pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7e6c911-c1ea-456d-8c44-c097fc66fedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "505f85fa-49bd-4829-b7a5-2137fd657a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_path=\"./BD/ejemplosk_embedding_db\"  #ruta donde se guardará la BBDD vectorizada\n",
    "\n",
    "#Creamos la BBDD de vectores a partir de los documentos y la función embeddings\n",
    "vector_store = SKLearnVectorStore.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=funcion_embedding,\n",
    "    persist_path=persist_path,\n",
    "    serializer=\"parquet\", #el serializador o formato de la BD lo definimos como parquet\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35a20e6d-29d3-4488-86b7-288a0a521e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuerza a guardar los nuevos embeddings en el disco\n",
    "vector_store.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f260d233-6854-4c91-aff5-106bfff911b8",
   "metadata": {},
   "source": [
    "Una vez ejecutado el anterior código, y apodemos ver en nuestro disco duro la base de datos creada en la carpeta BD y con denominación ejemplosk_embedding_db.\n",
    "\n",
    "### Búsqueda en la Base de Datos.\n",
    "\n",
    "Una vez creada la base de datos podremos ya hacer consultas de similitud de cadenas, para que nos encuentre en la BD los párrafos más similares al litereal que le pasamos. Además nos devuelve párrafos ordenados de mayor a menor similitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9a4204c-7970-45aa-b7aa-4a305fc13d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictablanda del general Berenguer (1930-1931)\n",
      "Artículo principal: Dictablanda de Dámaso Berenguer\n",
      "Tras la crisis económica de 1927 acentuada en 1929, la violenta represión de obreros e intelectuales y la falta de sintonía entre la burguesía y la dictadura, la monarquía, cómplice, será el objeto en cuestión a partir de la unión de toda la oposición en agosto de 1930 en el llamado Pacto de San Sebastián. Los gobiernos de Dámaso Berenguer, denominado la «dictablanda», y de Juan Bautista Aznar-Cabañas, no harán otra cosa que alargar la decadencia. Tras las elecciones municipales de 1931, el 14 de abril se proclama la Segunda República, dando así fin a la restauración borbónica en España.\n",
      "\n",
      "Segunda República española (1931-1936)\n",
      "Artículo principal: Segunda República española\n"
     ]
    }
   ],
   "source": [
    "#Creamos un nuevo documento que será nuestra \"consulta\" para buscar el de mayor similitud en nuestra Base de Datos de Vectores y devolverlo\n",
    "consulta = \"dame información de la Primera Guerra Mundial\"\n",
    "docs = vector_store.similarity_search(consulta)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15163e5b-608e-4c53-9199-5a312c2c968a",
   "metadata": {},
   "source": [
    "El resultado que obtenemos no es lo que realmente estamos buscando, pero hay que tener en cuenta que estamos trabajando en modo local y con resursos muy limitados debido a los escasos recursos que los ordenadores personales tienen para este tipo de trabajos de IA. Muy posiblemente si esto lo hacemos utilizando el api-key de OpenAi el resultado hubiera sido más acertado y además más rápido\n",
    "\n",
    "## Recuprar datos de una BD.\n",
    "\n",
    "Una vez creada la base de datos, y como ya los datos se han persistido y están almacenados en la base de datos, podemos recuperar en cualquier momento la información de esa base de datos y hacer consultas sobre la misma. A continuación se muestra cómo poder hacer esto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5534a007-66e0-4107-b08f-21d50115726f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Una instancia de la BBDD de vectores se ha cargado desde  ./BD/ejemplosk_embedding_db\n"
     ]
    }
   ],
   "source": [
    "vector_store_connection = SKLearnVectorStore(\n",
    "    embedding=funcion_embedding, persist_path=persist_path, serializer=\"parquet\"\n",
    ")\n",
    "print(\"Una instancia de la BBDD de vectores se ha cargado desde \", persist_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3bed41d2-2161-4758-8d49-c08317fda9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.sklearn.SKLearnVectorStore at 0x1cf3a034090>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a0cf54c7-2e6a-4c04-9c72-c9d17ad42270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guerra hispano-estadounidense\n",
      "Artículo principal: Guerra hispano-estadounidense\n",
      "España pierde Cuba, Filipinas y Puerto Rico: Cuba se rebeló contra España en el comienzo la Guerra de los Diez Años en 1868, dando como resultado la abolición de la esclavitud en las colonias españolas en el Nuevo Mundo. Los intereses estadounidenses en la isla, junto con la preocupación por el pueblo de Cuba, empeoraron las relaciones entre los dos países. La explosión del USS Maine lanzó la guerra de Cuba en 1898, en el que España sufrió un descalabro. Cuba obtuvo su independencia y España perdió sus últimas colonias del Nuevo Mundo: Puerto Rico, junto con Guam y las Filipinas fueron cedidas a los Estados Unidos por 20 millones de dólares. En 1899, España vendió su participación restante de las islas del Pacífico, las islas Marianas del Norte, islas Carolinas y Palaos, a Alemania y las posesiones coloniales españolas se redujeron al Marruecos español, Sahara Español y Guinea española, todo en África. El «desastre» de 1898 creó la generación del 98, un grupo de estadistas e intelectuales que exigían el cambio liberal del nuevo gobierno.\n"
     ]
    }
   ],
   "source": [
    "nueva_consulta = \"¿Qué paso en el siglo de Oro?\"\n",
    "docs = vector_store_connection.similarity_search(nueva_consulta)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4cdd8d-03aa-4224-a33b-3bb9dc4502db",
   "metadata": {},
   "source": [
    "## Alternativa con ChromaDB.\n",
    "\n",
    "La base de datos ChromaDB, también es muy utilizada para realizar este tipo de tareas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1bc77d7f-0ea2-475f-bbdc-ea8f0007db72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain_chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0dde476f-86fd-4e79-96e8-9c7749b29f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb #pip install chromadb en una terminal\n",
    "from langchain_chroma import Chroma #pip install langchain_chroma en una terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127a3c43-95dd-4e51-9513-e2df89df333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar en ChromaDB\n",
    "#db = Chroma.from_documents(docs, funcion_embedding,collection_name=\"langchain\",persist_directory='./ejemplo_embedding_db')\n",
    "#Se crean en el directorio persistente la carpeta con los vectores y otra con las string, aparte de una carpeta \"index\" que mapea vectores y strings\n",
    "# Fuerzar a guardar los nuevos embeddings en el disco\n",
    "#db.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97add63c-5d6e-4614-abc7-3461fb60d58a",
   "metadata": {},
   "source": [
    "## Añadir nueva información a la BD de vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "23a68112-7cb8-4c4b-a50b-8b1e6e93c4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar documento y dividirlo\n",
    "loader = TextLoader('Fuentes datos/Nuevo_documento.txt', encoding=\"utf8\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5aaa18d-2c79-4a6b-a5d4-565d512c368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=500)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c981c9a-86b7-498b-9d73-758154f82ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar en Chroma\n",
    "#db = Chroma.from_documents(docs, embedding_function,persist_directory='./ejemplo_embedding_db')\n",
    "# docs = db.similarity_search('insertar_nueva_búsqueda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9b032e-7b92-4450-9d3d-938f4c934cdb",
   "metadata": {},
   "source": [
    "## Comprensión y optimización de resultados a partir de LLMs.\n",
    "\n",
    "En el apartado anterior hemos visto cómo poder encontrar párrafos de un texto que se asimilan mucho a la consulta que estamos planteando. Pero el resultado que obtenemos no presenta el formato más adecuado para la respuesta que buscamos. En este apartado vamos a ver cómo podemos conseguir esto.\n",
    "\n",
    "No estamos realizando compresión en el sentido tradicional, sino que utilizamos un LLM para tomar una salida de texto de un documento de mayor tamaño y la limpia / optimiza en una salida más corta y relevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0019c88-4154-4594-8d7c-6da84a7035d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WikipediaLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import SKLearnVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "719a923e-ae00-4cfe-934d-7046d9f251a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\MisTrabajos\\IA_generativa\\venv\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file D:\\MisTrabajos\\IA_generativa\\venv\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    }
   ],
   "source": [
    "#cargamos documentos desde la wikipedia\n",
    "loader = WikipediaLoader(query='Lenguaje Python',lang=\"es\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158c4958-bb83-409d-91f4-4aebae9a7915",
   "metadata": {},
   "source": [
    "Obtenemos de esta manera un documento lo suficientemente grande como para poder trabajar con el para demostrar esta facilidad de LangChain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b955e6a6-16dd-4450-a04b-b2e47391937a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb5ac5a-96df-42d0-a26a-8ae0f4f24847",
   "metadata": {},
   "source": [
    "Procedemos a dividir el documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "81c043a1-4d2e-4a6b-a799-cc0f37d44bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 636, which is longer than the specified 500\n",
      "Created a chunk of size 515, which is longer than the specified 500\n",
      "Created a chunk of size 591, which is longer than the specified 500\n",
      "Created a chunk of size 542, which is longer than the specified 500\n",
      "Created a chunk of size 653, which is longer than the specified 500\n",
      "Created a chunk of size 738, which is longer than the specified 500\n"
     ]
    }
   ],
   "source": [
    "# División en fragmentos\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=500)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f6eb1fda-0c01-4c27-a30e-6899820d6b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a925ad0c-1fc3-431b-9887-d8a8ba5bb705",
   "metadata": {},
   "outputs": [],
   "source": [
    "funcion_embedding = OllamaEmbeddings(\n",
    "    model=\"llama3.2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b41f4a61-acb6-4141-8878-4c3cd9d43d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_path=\"./BD/ejemplo_wiki_bd\"  #ruta donde se guardará la BBDD vectorizada\n",
    "\n",
    "#Creamos la BBDD de vectores a partir de los documentos y la función embeddings\n",
    "vector_store = SKLearnVectorStore.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=funcion_embedding,\n",
    "    persist_path=persist_path,\n",
    "    serializer=\"parquet\", #el serializador o formato de la BD lo definimos como parquet\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "04874f1c-9c9e-4af6-97ff-92e65f6cf40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuerza a guardar los nuevos embeddings en el disco\n",
    "vector_store.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10df487-c772-4911-9e4f-c1a889a1a32e",
   "metadata": {},
   "source": [
    "Hacemos una consulta normal de similitud coseno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e8041c89-2a51-4f1c-8307-c607cee88f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solo cinco tipos de datos básicos\n",
      "No requiere declaración de variables.\n",
      "Soporte explícito para programación top-down.\n",
      "La anidación de instrucciones se indica mediante sangría, a través de la regla de fuera de juego.\n",
      "Precisión arbitraria, Listas y cadenas de tamaño ilimitado, y otras características que admiten la ortogonalidad y la facilidad de uso para los principiantes.\n",
      "Como sucede con otros intérpretes, ABC es, además de un lenguaje de programación, un entorno interactivo de trabajo. No requiere de declaraciones de variables, cuenta con el apoyo de la programación top-down. Proporciona una precisión aritmética infinita, ilimitada listas de cadenas, y otras características que da gran facilidad al uso de los principiantes. Sus diseñadores afirman que los programas de ABC son típicamente alrededor de una cuarta parte del tamaño de los programas equivalentes en lenguaje Pascal o en lenguaje C, y además es más legible. \n",
      "Originalmente fue una aplicación monolítica, dando lugar a una incapacidad para adaptarse a las nuevas exigencias, como la creación de una interfaz gráfica de usuario. Con ABC no se podía acceder directamente al sistema de archivos subyacente y el sistema operativo. \n",
      "Incluye un entorno de programación con sintaxis de edición-dirigida, sugerencias, variables persistentes y múltiples espacios de trabajo. \n",
      "ABC está disponible como un intérprete / compilador, actualmente en la versión 1.05.02. Además ha sido portado a Unix, DOS, Atari, y Apple Macintosh.\n",
      "ABC también tuvo una gran influencia en el diseño del lenguaje de programación Python, Guido van Rossum, quien desarrolló Python, que anteriormente trabajó durante varios años en el sistema ABC a principios de los años 1980.\n"
     ]
    }
   ],
   "source": [
    "#Creamos un nuevo documento que será nuestra \"consulta\" para buscar el de mayor similitud en nuestra Base de Datos de Vectores y devolverlo\n",
    "consulta = \"¿Por qué el lenguaje Python se llama así?\"\n",
    "docs = vector_store.similarity_search(consulta)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486aed1a-174e-4cae-add1-a8375d1d4c0f",
   "metadata": {},
   "source": [
    "Como podemos ver la respuesta obtenida ( como antes quizá sin mucho sentido para la pregunta formulada) presenta un aspecto que no es el más adecuado para la presentación a la persona que formula la pregunta. Por ello, a continuación vamos a ver cómo podemos reconducir esto para obtener un resultado  que se adapte más a nuestras pretensiones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a21fe48-e232-44df-9b6b-d729842d171c",
   "metadata": {},
   "source": [
    "### Consulta con compresión contextual usando LLMs.\n",
    "\n",
    "Para obtener el resultado pretendido, vamos a importar las siguientes librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9fb80c92-c1ff-4a16-b740-9b6df7003a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bce6d0e2-f45e-4873-85c9-e42321e4bed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"llama3.2\", #el parámetro temperatura define la aleatoriedad de las respuestas, temperatura = 0 significa el mínimo de aleatoriedad\n",
    "    temperature=0,\n",
    "    api_key='ollama', # required, but unused,\n",
    ") \n",
    "compressor = LLMChainExtractor.from_llm(llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fc885dda-67ea-40dc-941d-232b08dba9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=vector_store.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fa913f91-9881-4a37-b176-abcbaae04758",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: ollama. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m compressed_docs \u001b[38;5;241m=\u001b[39m \u001b[43mcompression_retriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m¿Por qué el lenguaje Python se llama así?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\MisTrabajos\\IA_generativa\\venv\\Lib\\site-packages\\langchain_core\\retrievers.py:259\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    257\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[1;32m--> 259\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    263\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[1;32mD:\\MisTrabajos\\IA_generativa\\venv\\Lib\\site-packages\\langchain\\retrievers\\contextual_compression.py:48\u001b[0m, in \u001b[0;36mContextualCompressionRetriever._get_relevant_documents\u001b[1;34m(self, query, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_retriever\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m     45\u001b[0m     query, config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_manager\u001b[38;5;241m.\u001b[39mget_child()}, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m     46\u001b[0m )\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m docs:\n\u001b[1;32m---> 48\u001b[0m     compressed_docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_compressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompress_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(compressed_docs)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\MisTrabajos\\IA_generativa\\venv\\Lib\\site-packages\\langchain\\retrievers\\document_compressors\\chain_extract.py:73\u001b[0m, in \u001b[0;36mLLMChainExtractor.compress_documents\u001b[1;34m(self, documents, query, callbacks)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents:\n\u001b[0;32m     72\u001b[0m     _input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_input(query, doc)\n\u001b[1;32m---> 73\u001b[0m     output_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain, LLMChain):\n\u001b[0;32m     75\u001b[0m         output \u001b[38;5;241m=\u001b[39m output_[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39moutput_key]\n",
      "File \u001b[1;32mD:\\MisTrabajos\\IA_generativa\\venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3016\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3014\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3015\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3016\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3017\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3018\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mD:\\MisTrabajos\\IA_generativa\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:284\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    280\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    281\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    283\u001b[0m         ChatGeneration,\n\u001b[1;32m--> 284\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    294\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mD:\\MisTrabajos\\IA_generativa\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:860\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    854\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    858\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    859\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\MisTrabajos\\IA_generativa\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:690\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    688\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 690\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    696\u001b[0m         )\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    698\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mD:\\MisTrabajos\\IA_generativa\\venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:925\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    924\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 925\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    929\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\MisTrabajos\\IA_generativa\\venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:790\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    788\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[0;32m    789\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 790\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[1;32mD:\\MisTrabajos\\IA_generativa\\venv\\Lib\\site-packages\\openai\\_utils\\_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\MisTrabajos\\IA_generativa\\venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:863\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    860\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    861\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    862\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    901\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    906\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\MisTrabajos\\IA_generativa\\venv\\Lib\\site-packages\\openai\\_base_client.py:1283\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1270\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1271\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1278\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1279\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1280\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1281\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1282\u001b[0m     )\n\u001b[1;32m-> 1283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mD:\\MisTrabajos\\IA_generativa\\venv\\Lib\\site-packages\\openai\\_base_client.py:960\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    958\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 960\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\MisTrabajos\\IA_generativa\\venv\\Lib\\site-packages\\openai\\_base_client.py:1064\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1061\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1063\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1064\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1067\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1068\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1072\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1073\u001b[0m )\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ollama. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "compressed_docs = compression_retriever.invoke(\"¿Por qué el lenguaje Python se llama así?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf20003d-f742-4a89-810f-2d06ad50a4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_docs[0].page_content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
