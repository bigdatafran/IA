{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(embeding)=\n",
    "# Embeddings con OpenAI\n",
    "Embeddings es un proceso mediante el cual se utiliza alguna tecnica/algoritmo que sea capaz de convertir palabras o texto a vectores de N dimensiones. Estos vectores contienen cierto nivel de información semantica sobre el texto o palabra. Por ejemplo, palabras que son muy similares van a tener valores cercanos en sus representaciones en vectores.\n",
    "\n",
    "Hay varios modelos que son capaces de hacer un embedding de nuestro texto, en este cuaderno estaremos utilizando el embedding de OpenAI, el cual tiene la capacidad de posicionas muy bien palabras o textos segun su semantica. Este es el mismo embedding que utiliza GPT3. En este cuaderno estarás haciendo embedding de un texto para despues poder buscar cosas dentro de este texto por medio de preguntas en lenguaje natural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos todas las dependencias requeridas, en este caso será Gradio para desarrollar la interfaz grafica y openai para realizar los llamados a su API \n",
    "#import gradio as gr\n",
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "#from openai.embeddings_utils import get_embedding\n",
    "#from openai.embeddings_utils import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la API Key para vincular el cuaderno con nuestra cuenta de OpenAI\n",
    "openai.api_key = \"sk-\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Que es y cómo usar embeddings\n",
    "Al hacer embedding de un dato, lo estamos convirtiendo a un vector numérico, datos similares estarán más cercanos entre si cuando semanticamente son similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se puede hacer embeeding de palabras o cadenas de texto\n",
    "palabras = [\"casa\", \"perro\", \"gato\", \"lobo\", \"leon\", \"zebra\", \"tigre\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario = {}\n",
    "for i in palabras:\n",
    "    diccionario[i] = get_embedding(i, engine=\"text-embedding-ada-002\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabra = \"gato\"\n",
    "print(\"Primeros 10 valores de {}:\\n\".format(palabra), diccionario[palabra][:10])\n",
    "print(\"\\n\")\n",
    "print(\"Número de dimensiones del dato embebido\\n\", len(diccionario[palabra]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparar dos embeddings\n",
    "Debido a que los embeddings son una representacion vectorial de los datos en un espacio latente, podemos medir la distancia entre dos vectores y asi obtener que tan similares son. Podemos comparar una palabra nueva o alguna de las que ya fueron embebidas \n",
    "OJO: No necesariamente es similitud al objeto. Ej. perro y gato aun siendo \"opuestos\" semanticamente estan cerca pues tienen una relación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_palabra = \"agujero negro\" # Palabra nueva a comparar\n",
    "palabra_comparar = \"perro\" # Palabra del diccionario con la que compararemos la nueva palabra\n",
    "n_palabra_embed = get_embedding(n_palabra, engine=\"text-embedding-ada-002\")\n",
    "similitud = cosine_similarity(diccionario[palabra_comparar], n_palabra_embed)\n",
    "print(similitud)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sumar embeddings\n",
    "Como los vectores contienen valores numericos, podemos sumarlos y el resultado será un nuevo vector de un concepto que una los elementos sumados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suma dos listas usando pandas\n",
    "sumados = (pd.DataFrame(diccionario[\"leon\"])) + (pd.DataFrame(diccionario[\"zebra\"]))\n",
    "len(sumados)\n",
    "\n",
    "for key, value in diccionario.items():\n",
    "    print(key, \":\", cosine_similarity(diccionario[key], sumados))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicacion de un Chatbot\n",
    "\n",
    "Usaremos Gradio para hacer una interfaz básica donde podremos hacer preguntas y obtendremos una respuesta. \n",
    "Para esto reutilizaremos lo que hemos visto hasta el momento pero usaremos el archivo de **chatbot_qa.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_text(path=\"texto.csv\"):\n",
    "    conocimiento_df = pd.read_csv(path)\n",
    "    conocimiento_df['Embedding'] = conocimiento_df['texto'].apply(lambda x: get_embedding(x, engine='text-embedding-ada-002'))\n",
    "    conocimiento_df.to_csv('embeddings.csv')\n",
    "    return conocimiento_df\n",
    "\n",
    "def buscar(busqueda, datos, n_resultados=5):\n",
    "    busqueda_embed = get_embedding(busqueda, engine=\"text-embedding-ada-002\")\n",
    "    datos[\"Similitud\"] = datos['Embedding'].apply(lambda x: cosine_similarity(x, busqueda_embed))\n",
    "    datos = datos.sort_values(\"Similitud\", ascending=False)\n",
    "    return datos.iloc[:n_resultados][[\"texto\", \"Similitud\", \"Embedding\"]]\n",
    "\n",
    "texto_emb = embed_text(\"./chatbot_qa.csv\")\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    busqueda = gr.Textbox(label=\"Buscar\")\n",
    "    output = gr.DataFrame(headers=['texto'])\n",
    "    greet_btn = gr.Button(\"Preguntar\")\n",
    "    greet_btn.click(fn=buscar, inputs=[busqueda, gr.DataFrame(texto_emb)], outputs=output)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesar datos de un PDF\n",
    "Haremos ahora un ejemplo donde leemos un PDF para poder hacer preguntas y traer un exctracto del PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain pypdf\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "loader = PyPDFLoader(\"./mtg.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un elemento por cada página\n",
    "pages[3].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objeto que va a hacer los cortes en el texto\n",
    "split = CharacterTextSplitter(chunk_size=300, separator = '.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos = split.split_documents(pages) # Lista de textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(textos[0].page_content)\n",
    "#print(textos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraemos la parte de page_content de cada texto y lo pasamos a un dataframe\n",
    "textos = [str(i.page_content) for i in textos] #Lista de parrafos\n",
    "parrafos = pd.DataFrame(textos, columns=[\"texto\"])\n",
    "print(parrafos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parrafos['Embedding'] = parrafos[\"texto\"].apply(lambda x: get_embedding(x, engine='text-embedding-ada-002')) # Nueva columna con los embeddings de los parrafos\n",
    "parrafos.to_csv('MTG.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La misma funcion del chatbot de pregunts y respuestas\n",
    "def embed_text(path=\"texto.csv\"):\n",
    "    conocimiento_df = pd.read_csv(path)\n",
    "    conocimiento_df['Embedding'] = conocimiento_df['texto'].apply(lambda x: get_embedding(x, engine='text-embedding-ada-002'))\n",
    "    conocimiento_df.to_csv('mtg-embeddings.csv')\n",
    "    return conocimiento_df\n",
    "\n",
    "def buscar(busqueda, datos, n_resultados=5):\n",
    "    busqueda_embed = get_embedding(busqueda, engine=\"text-embedding-ada-002\")\n",
    "    datos[\"Similitud\"] = datos['Embedding'].apply(lambda x: cosine_similarity(x, busqueda_embed))\n",
    "    datos = datos.sort_values(\"Similitud\", ascending=False)\n",
    "    return datos.iloc[:n_resultados][[\"texto\", \"Similitud\", \"Embedding\"]]\n",
    "\n",
    "texto_emb = parrafos\n",
    "with gr.Blocks() as demo:\n",
    "    busqueda = gr.Textbox(label=\"Buscar\")\n",
    "    output = gr.DataFrame(headers=['texto'])\n",
    "    greet_btn = gr.Button(\"Preguntar\")\n",
    "    greet_btn.click(fn=buscar, inputs=[busqueda, gr.DataFrame(texto_emb)], outputs=output)\n",
    "\n",
    "demo.launch()\n",
    "\n",
    "\n",
    "# resp = buscar(\"Con cuanta vida empiezo?\", parrafos, 5) # Reutilizamos la funcion de \"buscar\" del app de gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resp = buscar(\"Con cuanta vida empiezo?\", parrafos, 5) # Reutilizamos la funcion de \"buscar\" del app de gradio\n",
    "# print(resp.texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "e3e99415c7ce2cb9b8857283077fa90c1d7ffec737ddc9f365b1225d7f13a404"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
