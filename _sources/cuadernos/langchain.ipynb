{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dab750dd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Introducción a LangChain\n",
    "\n",
    "En el ámbito de la inteligencia artificial y el desarrollo de aplicaciones basadas en modelos de lenguaje, **LangChain** se ha convertido en una de las herramientas más innovadoras y versátiles. Se trata de un framework diseñado para facilitar la integración de **modelos de lenguaje de gran tamaño (LLMs, por sus siglas en inglés)** en aplicaciones dinámicas e interactivas. Su objetivo principal es simplificar el desarrollo de flujos de trabajo complejos que combinan diferentes fuentes de datos, almacenamiento de memoria, ejecución de agentes y procesamiento estructurado de información.  \n",
    "\n",
    "Una de las características más destacadas de LangChain es su capacidad para conectar modelos de lenguaje con bases de datos, APIs y documentos externos, permitiendo a los desarrolladores crear aplicaciones avanzadas como **asistentes conversacionales, motores de búsqueda mejorados, generación de código automático y automatización de tareas empresariales**. Para lograrlo, LangChain proporciona módulos modulares y componibles que permiten personalizar y optimizar la interacción con los modelos de IA.  \n",
    "\n",
    "El framework se basa en cinco componentes clave:  \n",
    "\n",
    "1. **Modelos de lenguaje**: Integra modelos como OpenAI GPT, Hugging Face Transformers, Cohere y muchos más, facilitando su uso en diversas tareas de procesamiento del lenguaje natural.  \n",
    "2. **Encadenamiento de procesos (Chains)**: Permite combinar múltiples pasos en una sola secuencia lógica para tareas más avanzadas.  \n",
    "3. **Memoria**: Proporciona almacenamiento de contexto en conversaciones para mejorar la coherencia y continuidad de las interacciones.  \n",
    "4. **Recuperación y conexión con datos externos**: Facilita el acceso a bases de datos, documentos y APIs para enriquecer las respuestas del modelo.  \n",
    "5. **Agentes y herramientas**: Permite el uso de modelos como agentes capaces de tomar decisiones y ejecutar acciones basadas en entradas dinámicas.  \n",
    "\n",
    "El uso de LangChain está revolucionando sectores como la **automatización empresarial, la educación, el soporte al cliente y la investigación**, ofreciendo soluciones más inteligentes y adaptadas a las necesidades del usuario. Su flexibilidad y capacidad de integración hacen de este framework una opción ideal para quienes buscan desarrollar aplicaciones de inteligencia artificial con capacidades conversacionales avanzadas y una gestión eficiente del conocimiento.  \n",
    "\n",
    "En conclusión, LangChain representa un avance significativo en la forma en que los modelos de lenguaje interactúan con entornos del mundo real. Su estructura modular, junto con su compatibilidad con diferentes fuentes de información, permite a los desarrolladores crear soluciones más sofisticadas e inteligentes, abriendo un abanico de posibilidades en el campo de la inteligencia artificial aplicada.  \n",
    "\n",
    "\n",
    "## Apartados de Langchain.\n",
    "\n",
    "Langchain cuenta con cinco grandes bloques o apartados: Models, Prompts, indexes, memori, cahin y agentes:\n",
    "\n",
    "\n",
    "* Models: Indica la red neuronal que se va a uitilizar.\n",
    "\n",
    "* Promts: son los textos enviados al modelo. Pueden ser de diferentes tipos:\n",
    "\n",
    "1.- Promt template: Son textos que sirven como guia del modelo\n",
    "\n",
    "2.- chat promt template. Modelos para los chats\n",
    "\n",
    "3.- promt value. Seria el texto completo ya formateado\n",
    "\n",
    "4.- Example selector. Ayuda y genera mejor las respuestas.\n",
    "\n",
    "* Index. Para dar acceso a distinta fuentes de datos. Permite indexar un gran volumen de documentos. Pueden ser:\n",
    "\n",
    "1.- Document Loader: abrir, cargar y procesar diferentes archivos.\n",
    "\n",
    "2.- Text spliter: partir un documento en bloques más cortos\n",
    "\n",
    "3.- Vector stores: Donde almacena los embedings\n",
    "\n",
    "4.- Retrieves. Ayuda a traer información de algún documento específico\n",
    "\n",
    "* Memory: Dar memoria para por ejemplo los chats\n",
    "\n",
    "* cadenas/chain: Permitir unir modelos o cadenas entre sí\n",
    "\n",
    "* Agentes: Dar acceso a ciertas herramientas para solucionar mejor una determinada tarea\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e546dfbc-9103-40df-a57b-096cdea22f0d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Cómo trabajar con LangChain en remoto\n",
    "\n",
    "Existen métodos de pagos con los que se puede trabajar en IA de forma remota. Nosotros y con el fin de que el lector pueda adquirir conocimientos sobre esta materia sin incurrir en ningún costo, hemos desarrollado la mayor parte de los apartados en forma local de manera que no se genere coste alguno.\n",
    "\n",
    "No obstante para aquellos que quieran saber cómo proceder mediante alguno de los métodos de pago existente, se invita al lector a [visitar este apartado](pago).\n",
    "\n",
    "## Como trabajar con Google Colab.\n",
    "```{index} Colab\n",
    "```\n",
    "\n",
    "Google Colab es una buena herramienta computacional para realizar trabajos con LLM, en este apartado vamos a mostrar dos formas de poder trabajar este tipo de modelos.\n",
    "\n",
    "1.- Descargando directamente el model de Hugging Face, como se [muestra en este apartado](llama2), y se <a href=\"https://www.youtube.com/watch?v=Xc5xNRM_hvk\" target=\"_blank\"> pude ver en este vídeo </a>.\n",
    "\n",
    "2.- Otra opción interesante es instalar en Colab *colab-xtera\" y alli instalar ollama. La forma de proceder en este caso <a href=\"https://www.youtube.com/watch?v=4tVdDLrucOk\" target=\"_blank\"> la puedes ver en este vídeo </a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cce8e4-cc32-4d13-915b-927c5c5c0777",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Cómo trabajar con LangChain en local.\n",
    "\n",
    "Para poder trabajar en local, sin necesidad de tener conexión con proveedor de pago, lo que vamos a hacer es trabajar con ollama, cuyo formato de uso lo puedes ver dentro de este trabajo y en concreto [en este apartado](ollama1), al que se invita a ir al lector si no conoce la materia. En adelante se presupone que el lector conoce esta herramienta para poder trabajar con modelos en local.\n",
    "\n",
    "Una vez se tenga ese conocimiento, como inicio lo que vamos a crear una serie de solicitudes de entrada básicas para modelos y vamos a ver cómo gestionar los resultados que nos devuelven los LLM.\n",
    "\n",
    "En esta sección nuestro interés se va a centrar en las funcionalidades básicas y la sintaxis que se necesita para hacer esto con LangChain.\n",
    "\n",
    "El uso de Langchain y el componente Modelo IO nos permitirá construir cadenas más adelante, pero también nos dará más flexibilidad para cambiar de proveedor de LLM en el futuro , ya que la sintaxis está estandarizada en todos los LLM y solo cambian los parámetros o argumentos proporcionados.\n",
    "\n",
    "Debemos tener en cuenta 2 parámetros importantes en las solicitudes a las APIs de los LLMs:\n",
    "\n",
    "![](fig/tipos.PNG)\n",
    "\n",
    "Para verificar cómo conectar a los diferentes LLMs integrados en Langchain, ver el siguiente enlace :\n",
    "\n",
    "https://python.langchain.com/v0.2/docs/integrations/chat/\n",
    "\n",
    "Procedemos a continuación a mostrar un ejemplo sobre la creación de un chat en local utilizando el modelo ue tenemos cargado en ollama y que se denomina 'llama3.1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aaba2ca-dff7-457f-89d7-29be97b7e27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=\"llama3.2\",\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', # required, but unused,\n",
    ")\n",
    "\n",
    "resultado = chat.invoke([HumanMessage(content=\"¿Puedes decirme donde se encuentra cáceres?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5513a0ae-018b-4c51-a9c5-cb4a26d7db95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='¡Claro! Cáceres es una ciudad española ubicada en la región de Extremadura, en el sur del país. Está situada en un valle rodeado por las Sierras de Cáceres y el arroyo Trucha, lo que le da un entorno natural muy pintoresco.\\n\\nCáceres es la capital de la provincia de Cáceres y cuenta con una rica historia y cultura, siendo considerada Patrimonio de la Humanidad por la UNESCO desde 1994. La ciudad está rodeada por una muralla árabe que se conserva en gran parte, lo que le da un carácter único.\\n\\nLa ciudad tiene una población de alrededor de 98.000 habitantes y es un importante centro cultural, económico y turístico en la región de Extremadura.\\n\\n¿Quieres saber más sobre Cáceres o sobre algo específico relacionado con la ciudad?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 207, 'prompt_tokens': 38, 'total_tokens': 245, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'llama3.2', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-ccdccb38-2824-4f53-b042-be7f2429bbf7-0', usage_metadata={'input_tokens': 38, 'output_tokens': 207, 'total_tokens': 245, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b867397-12bf-4af9-9180-55c529df4de4",
   "metadata": {},
   "source": [
    "Si queremos ver sólo el resultado buscado, debemos ejecutar la siguiente instrucción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b1e00e6-4f63-4c3e-888d-5230d0585264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cáceres es una ciudad situada en el oeste de la península ibérica, España.\\nSe encuentra ubicada a una altura de 413 msnm y su código postal es 10001. La ciudad tiene más de 97.000 habitantes y pertenece a la comunidad autónoma de Extremadura'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97546bd4-72c4-4fd7-bef0-ce85a51c7a1b",
   "metadata": {},
   "source": [
    "```{index} SystemMessage,HumanMessage\n",
    "```\n",
    "Especificamos el SystemMessage para definir la personalidad que debe tomar el sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd3d2664-9fbd-48de-9bfb-d20df4968be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = chat.invoke([SystemMessage(content='Eres un historiador que conoce los detalles de todas las ciudades del mundo'),\n",
    "               HumanMessage(content='¿Puedes decirme dónde se encuentra Cáceres')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87075aa1-a2ae-4a32-95b6-41cb6eecc1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¡Un placer hablar de España! Cáceres es una ciudad ubicada en la comunidad autónoma de Extremadura, en el suroeste peninsular. Se sitúa en la comarca del Valle del Alagón, capital de la provincia homónima y tiene una población de alrededor de 97.000 habitantes.\\n\\nGeométricamente hablando, Cáceres se encuentra a unos 280 km al sureste de Madrid, capital de España. La ciudad es un importante centro turístico, Patrimonio de la Humanidad declarado por la UNESCO en el año 1987, debido a su rica historia que refleja su paso por diferentes culturas y civilizaciones: desde el Imperio Romano hasta la Edad Moderna.\\n\\nSu emblema es la Plaza Mayor, un conjunto arquitectónico de época colonial y gótica, con una belleza y variedad únicas. También se destaca la rica arquitectura mudéjar que se encuentra en varias manzanas cercanas a esta conocida plaza central.\\n\\n¿Es esta información útil para ti? ¿Tienes algún otro lugar al que me pido que te indique con precisión geográfica y también cultural?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb2af10-d468-4db8-a3d0-2f24e6b36d01",
   "metadata": {},
   "source": [
    "Se pueden obtener varios resultados invocando al chat de OpenAI con \"generate\". Observar en este ejemplo la importancia que tiene el dar una información previa al modelo para indicar qué tipo de respuesta nos va a dar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc76d89f-d6b3-4595-929e-d3e2ae16f280",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = chat.generate(\n",
    "    [\n",
    "        [SystemMessage(content='Eres un historiador que conoce los detalles de todas las ciudades del mundo'),\n",
    "         HumanMessage(content='¿Puedes decirme dónde se encuentra Cáceres')],\n",
    "        [SystemMessage(content='Eres un joven rudo que no le gusta que le pregunten, solo quiere estar de fiesta'),\n",
    "         HumanMessage(content='¿Puedes decirme dónde se encuentra Cáceres')]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9617ee8-fa1a-420b-a063-43fa3a71e240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claro! Cáceres es una ciudad situada en la comunidad autónoma de Extremadura, España. Se encuentra ubicada en la llanura de Trujillo, al noreste de la provincia homónima, muy cerca del río Almonte.\n",
      "\n",
      "Cáceres es conocida como \"la Roma de la Meseta\" porque cuenta con un importante y bien conservado patrimonio histórico y arquitectónico medieval, con casas blasonadas y edificios que datan de la época de los Reyes Católicos. Es también el corazón de la Ruta Jacobea en Extremadura.\n",
      "\n",
      "La ciudad tiene una importancia cultural y arquitectónica significativa por su historia medieval y moderna, destacando monumentos como La Corachola, El Obispo, El Císter, La Concepción o la iglesia de Santiago. Cáceres es también conocida por celebrar festivales y actuaciones teatrales de renombre durante gran parte del año. Su carácter y cultura le han otorgado un importante valor histórico, turístico y patrimonial en España y todo el mundo.\n",
      "\n",
      "¿Hay alguna otra pregunta más sobre Cáceres o ¿le gustaría saber algo más sobre una ciudad specific que esté interesada por su historia?\n"
     ]
    }
   ],
   "source": [
    "#Resultado con primer sistema\n",
    "print(resultado.generations[0][0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d3a9a59-b7f1-4b09-b8bd-ef225f4e21ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Me enfada un poco porque me estás molestando mientras preparo mi fiesta* ¡Cáceres! ¡Ja! Está en Extremadura, idiota. ¿No sabías eso? *Sacudo la cabeza y vuelvo a mirar hacia el rincón donde está funcionando una música*\n"
     ]
    }
   ],
   "source": [
    "#Resultado con segundo sistema\n",
    "print(resultado.generations[1][0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11497ae3-30fb-4329-b638-b7e097d672c7",
   "metadata": {},
   "source": [
    "## Las plantillas (templates) en LangChain.\n",
    "```{index} Plantillas, Templates\n",
    "```\n",
    "* Las plantillas nos permiten configurar y modificar fácilmente nuestras indicaciones de entrada para las\n",
    "llamadas de LLM.\n",
    "• Las plantillas ofrecen un enfoque más sistemático para pasar variables a solicitudes de modelos, en lugar de\n",
    "usar literales de cadena f o llamadas . format (), PromptTemplate las convierte en nombres de parámetros de\n",
    "función que podemos pasar.\n",
    "• Es recomendable usar plantillas para estandarizar los mensajes que enviamos a los LLMs para mayor\n",
    "flexibilidad y facilidad en futuros usos.\n",
    "\n",
    "Veamos cómo utilizar estas plantillas en LangChain. Primero importamos las librerías:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86999ceb-9b2f-425d-9f3e-a374f60859aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeca29a-4c6c-44ef-8d09-830c1aeef8cb",
   "metadata": {},
   "source": [
    "Y después procedemeos a crear diferentes plantillas. Comenzamos con una plantilla para el sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0a04ec6-1aa2-4eb3-8e6f-a2b3e0747ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tiempo_lectura', 'tipo_coches']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creamos la plantilla del sistema (system_template)\n",
    "system_template=\"Eres una IA especializada en coches de tipo {tipo_coches} y generar artículos que se leen en {tiempo_lectura}.\"\n",
    "# Las variables las metemeos entre corchetes\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "# Mostramos las variables que admite esta plantilla\n",
    "system_message_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21090cdd-4272-4ab7-851c-f274a2159c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['peticion_tipo_motor']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#De forma similar al procedimiento anterior, creamos la plantilla de usuario (human_template)\n",
    "human_template=\"Necesito un artículo para vehículos con motor {peticion_tipo_motor}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "# También mostramos las variables que admite\n",
    "human_message_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3dfce83-e23d-48c9-a710-15ef4aad2b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['peticion_tipo_motor', 'tiempo_lectura', 'tipo_coches']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creamos una plantilla de chat con la concatenación tanto de mensajes del sistema como del humano\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "# Los nombres de las variables, serán todas las definidas anteriormente\n",
    "chat_prompt.input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2181a82-0f87-40f7-847b-33da0578f0c1",
   "metadata": {},
   "source": [
    "Una vez definida la plantilla, lo que nos queda es introducir los valores concretos que queremos tenga las variables definidas anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3488f271-2c11-4950-b742-ab685ba1ea7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Eres una IA especializada en coches de tipo japoneses y generar artículos que se leen en 10 min.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Necesito un artículo para vehículos con motor híbrido enchufable', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Completar el chat gracias al formateo de los mensajes\n",
    "chat_prompt.format_prompt(peticion_tipo_motor=\"híbrido enchufable\", tiempo_lectura=\"10 min\", tipo_coches=\"japoneses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cb555bc-791e-425c-ab6a-33696324d06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformamos el objeto prompt a una lista de mensajes y lo guardamos en \"solicitud_completa\" que es lo que pasaremos al LLM finalmente\n",
    "solicitud_completa = chat_prompt.format_prompt(peticion_tipo_motor=\"híbrido enchufable\", tiempo_lectura=\"10 min\", tipo_coches=\"japoneses\").to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4374e722-9bc5-4afd-a697-32e62af334f2",
   "metadata": {},
   "source": [
    "Con esto ya tenemos completada nuestra plantilla y lista para que pueda ser procesada pro el LLM con el que estemos trabajando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4acbc40c-ff33-4ef0-8dfb-83644c1b952d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=\"llama3.2\",\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', # required, but unused,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7a6147c-1418-4f6d-ada8-c848aac5ea6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='**Descubre la Fuerza del Movimiento Sostenible: Coches Híbridos Enchufeables**\\n\\nEn la era del desarrollo sostenible, los fabricantes de automóviles están innovando y ofreciendo una nueva generación de vehículos que no solo son eficientes en términos de combustible sino también compatibles con nuestros objetivos ambientales. Entre estos avanzados vehículos se encuentran los coches híbridos enchufables (HEVs, por sus siglas en inglés), diseñados para combinar la potencia del motor convencional con la eficiencia energética de una batería eléctrica cargable.\\n\\n**Beneficios del Moto-Hybrid Enchufable**\\n\\n1.  **Mayor Eficiencia Energética:** Gracias a su capacidad para recargar la batería mediante el enchufe eléctrico, los coches híbridos enchufables pueden aprovechar al máximo sus ventajas en todos los aspectos: desde ahorrar combustible hasta reducir las emisiones contaminantes.\\n\\n2.  **Menor Consumo de Combustibles:** Como estos vehículos combinan el movimiento eléctrico y diesel, su rendimiento general es mucho mejor que sus equivalentes híbridos o eléctricos tradicionales, lo que los convierte en una opción ideal para aquellos que buscan reducir su huella de carbono sin sacrificar la autonomía.\\n\\n3.  **Menor Impacto Ambiental:** Al recargar las baterías con energías renovables (electricidad procedente de fuentes limpias como paneles solares), los híbridos enchufables pueden estar completamente integrados dentro de un modelo de transporte responsable y sostenible.\\n\\n4.  **Opciones en el Mercado:** Diversos fabricantes, desde Toyota hasta Hyundai, han introducido modelos híbridos con conectividad eléctrica en sus líneas de producción, lo que ofrece a los consumidores una amplia paleta de opciones para elegir.\\n\\n5.  **Economía y Asequibilidad:** Contrariamente a la creencia popular, los coches híbridos enchufables están volviendo más económicos para todos. Su eficiencia energética implica una disminución inmediata en el consumo de combustible que tradicionalmente consumen estos modelos híbridos.\\n\\n**Consideraciones Importantes**\\n\\n-   **Costos Iniciales vs. Ahorro a Largo Plazo:** Si bien los cotos de inicialidad son altos, las proyectadas economías no tardarán en compensar el costo del vehículo y serán una adición beneficiosa y rentable para cualquier familia.\\n\\n-   **Infraestructuras de Carga**: Como es un requisito esencial que se tenga acceso a puntos de carga (estaciones de servicio compatibles con enchufes) cerca de los lugares principales como en viajes a larga distancia o trabajos lejanos, también es necesario tener siempre presencia de estos servicios. Las áreas urbanizadas tienden a tener más oferta pero no en todas las ciudades pequeñas hay tanto suministro.\\n\\n-   **Efecto del Creciente de la Demanda:** Gracias al aumento de los vehículos híbridos enchufables en el mercado, está empezando a configurarse una cultura más eficiente y consciente dentro de nuestra sociedad ya que todos se vuelven usuarios seguros con estos sistemas de energía renovable.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 742, 'prompt_tokens': 60, 'total_tokens': 802, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'llama3.1', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-f6d3991e-c5c0-48bf-bf8a-e1f5ce2cf6dc-0', usage_metadata={'input_tokens': 60, 'output_tokens': 742, 'total_tokens': 802, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = chat.invoke(solicitud_completa)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64166e1a-df72-4060-a60a-f8cecd3c6070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Descubre la Fuerza del Movimiento Sostenible: Coches Híbridos Enchufeables**\\n\\nEn la era del desarrollo sostenible, los fabricantes de automóviles están innovando y ofreciendo una nueva generación de vehículos que no solo son eficientes en términos de combustible sino también compatibles con nuestros objetivos ambientales. Entre estos avanzados vehículos se encuentran los coches híbridos enchufables (HEVs, por sus siglas en inglés), diseñados para combinar la potencia del motor convencional con la eficiencia energética de una batería eléctrica cargable.\\n\\n**Beneficios del Moto-Hybrid Enchufable**\\n\\n1.  **Mayor Eficiencia Energética:** Gracias a su capacidad para recargar la batería mediante el enchufe eléctrico, los coches híbridos enchufables pueden aprovechar al máximo sus ventajas en todos los aspectos: desde ahorrar combustible hasta reducir las emisiones contaminantes.\\n\\n2.  **Menor Consumo de Combustibles:** Como estos vehículos combinan el movimiento eléctrico y diesel, su rendimiento general es mucho mejor que sus equivalentes híbridos o eléctricos tradicionales, lo que los convierte en una opción ideal para aquellos que buscan reducir su huella de carbono sin sacrificar la autonomía.\\n\\n3.  **Menor Impacto Ambiental:** Al recargar las baterías con energías renovables (electricidad procedente de fuentes limpias como paneles solares), los híbridos enchufables pueden estar completamente integrados dentro de un modelo de transporte responsable y sostenible.\\n\\n4.  **Opciones en el Mercado:** Diversos fabricantes, desde Toyota hasta Hyundai, han introducido modelos híbridos con conectividad eléctrica en sus líneas de producción, lo que ofrece a los consumidores una amplia paleta de opciones para elegir.\\n\\n5.  **Economía y Asequibilidad:** Contrariamente a la creencia popular, los coches híbridos enchufables están volviendo más económicos para todos. Su eficiencia energética implica una disminución inmediata en el consumo de combustible que tradicionalmente consumen estos modelos híbridos.\\n\\n**Consideraciones Importantes**\\n\\n-   **Costos Iniciales vs. Ahorro a Largo Plazo:** Si bien los cotos de inicialidad son altos, las proyectadas economías no tardarán en compensar el costo del vehículo y serán una adición beneficiosa y rentable para cualquier familia.\\n\\n-   **Infraestructuras de Carga**: Como es un requisito esencial que se tenga acceso a puntos de carga (estaciones de servicio compatibles con enchufes) cerca de los lugares principales como en viajes a larga distancia o trabajos lejanos, también es necesario tener siempre presencia de estos servicios. Las áreas urbanizadas tienden a tener más oferta pero no en todas las ciudades pequeñas hay tanto suministro.\\n\\n-   **Efecto del Creciente de la Demanda:** Gracias al aumento de los vehículos híbridos enchufables en el mercado, está empezando a configurarse una cultura más eficiente y consciente dentro de nuestra sociedad ya que todos se vuelven usuarios seguros con estos sistemas de energía renovable.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521bc2c7-713f-4f8d-ac67-2df5b9e34b97",
   "metadata": {},
   "source": [
    "## Parsear y procesar la salida.\n",
    "```{index} parseadores, Format_instructions\n",
    "```\n",
    "\n",
    "A menudo, al conectar la salida de un LLM (modelo de lenguaje grande), necesitas que esté en un formato particular, por ejemplo, puedes querer un objeto datetime de Python o un objeto JSON.\n",
    "\n",
    "LangChain viene con utilidades de análisis que te permiten convertir fácilmente las salidas en tipos de datos\n",
    "precisos gracias a los **parseadores**.\n",
    "\n",
    "Los elementos claves de estos parseadores son los siguientes:\n",
    "\n",
    "* Método parse (): Método concreto para evaluar la cadena de texto string ) y parsearla al tipo deseado.\n",
    "\n",
    "* Format_instructions : Una cadena de texto extra que Langchain añade al final del prompt para asistir y facilitar la interpretación por el LLM del formato deseado.\n",
    "\n",
    "Si no consigues el resultado parseado correctamente (por ejemplo, la respuesta del LLM es más extensa que únicamente una fecha que quieras parsear ), hay dos soluciones:\n",
    "\n",
    "1.- Usar parseador Auto fix\n",
    "\n",
    "2.- Usar un “ system prompt ” para dar mayor detalle al LLM de cómo debe actuar y responder.\n",
    "\n",
    "Veamos algunos ejemplos prácticos para dejar más claro cómo se puede operar en LangChain con estos parseadores. Primero impostamos librerías necesarias e instanciamos un modelo de chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7df462e-3195-4be2-acbf-9a7ba65f670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain.prompts import PromptTemplate, SystemMessagePromptTemplate,ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=\"llama3.2\",\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', # required, but unused,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8942897-ed66-42b3-8f62-09ce4e4813bd",
   "metadata": {},
   "source": [
    "### Parsear lista elementos separados por comas.\n",
    "\n",
    "Este puede ser el caso que necesitemos obtener una salida de los elementos que después sean procesados como un fichero de tipo csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1748af6c-ef46-4f66-a24d-5f4b64ee3bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "format_instructions = output_parser.get_format_instructions() \n",
    "#Nos devuelve las instrucciones que va a pasar al LLM en función del parseador concreto\n",
    "print(format_instructions)\n",
    "# Como vemos es una instrucción que el parseador manda al LLM para obtener la lista separada por comas.\n",
    "# Viene en ingles, pero funciona perfectamente si trabajamos en castellano"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab11e5d-bf1a-4217-bafc-d8eb947c102f",
   "metadata": {},
   "source": [
    "Vamos a ver un ejemplo imaginario. Suponemos que nos ha devuelto una serie de palabras, separadas por comas. Entonces vamos a ver como pasar eso a una lista que contenga las palabras anteriores que están separadas pro comas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f33bd01a-aba5-4e8a-8a70-b5413e5ebeaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coche', 'árbol', 'carretera']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Respuesta imaginaria\n",
    "respuesta = \"coche, árbol, carretera\"\n",
    "output_parser.parse(respuesta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caaec67-a04d-40d9-9c2c-eda7368ee55f",
   "metadata": {},
   "source": [
    "Veamos un ejemplo más concreto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0c14993-6c92-40c1-8502-19cc889e4706",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos la plantilla de usuario (human_template) con la concatenación de la variable \"request\" (la solicitud) y la variable \"format_instructions\" con \n",
    "#las instrucciones adicionales que le pasaremos al LLM\n",
    "human_template = '{request}\\n{format_instructions}'\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9c9c04a-fe52-4e8c-810e-5aca1ddfd6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='dime 5 características de los coches americanos\\nYour response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creamos el prompt y le damos formato a las variables\n",
    "chat_prompt = ChatPromptTemplate.from_messages([human_prompt])\n",
    "\n",
    "chat_prompt.format_prompt(request=\"dime 5 características de los coches americanos\",\n",
    "                   format_instructions = output_parser.get_format_instructions()) #Las instrucciones son las que proporciona el propio parseador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ac93514-1fd7-4da1-9a71-33ae85736db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformamos el objeto prompt a una lista de mensajes y lo guardamos en \"solicitud_completa\" que es lo que pasaremos al LLM finalmente\n",
    "solicitud_completa = chat_prompt.format_prompt(request=\"dime 5 características de los coches americanos\",\n",
    "                   format_instructions = output_parser.get_format_instructions()).to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a86bfca5-c4e3-42b3-a03a-aa18b3c8f95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat.invoke(solicitud_completa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49d0109e-d816-4230-be36-fa7853d41fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¡Claro! Aquí te presento 5 características comunes de los coches americanos:\\n\\nMusculosidad, potencia, tamaño, estilo clásico y capacidad de combustible.\\n\\nNota: Es importante mencionar que estas características pueden variar dependiendo del fabricante y el modelo específico, pero generalmente se consideran características típicas de la industria automotriz estadounidense.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34ac5803-3c2d-4989-af9d-cfb4b26cf304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['¡Claro! Aquí te presento 5 características comunes de los coches americanos:',\n",
       " 'Musculosidad',\n",
       " 'potencia',\n",
       " 'tamaño',\n",
       " 'estilo clásico y capacidad de combustible.',\n",
       " 'Nota: Es importante mencionar que estas características pueden variar dependiendo del fabricante y el modelo específico',\n",
       " 'pero generalmente se consideran características típicas de la industria automotriz estadounidense.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertir a la salida esperada\n",
    "output_parser.parse(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d30de24-f204-4e59-b702-efaccb21b679",
   "metadata": {},
   "source": [
    "### Parseador en formato de fechas\n",
    "\n",
    "Veamos ahora cómo podemos parsear una fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3890c939-1495-4ed9-9f9c-1b4d2b982d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\n",
      "\n",
      "Examples: 0919-07-12T14:00:53.746254Z, 1030-04-28T09:34:56.105804Z, 0519-11-03T22:48:46.940556Z\n",
      "\n",
      "Return ONLY this string, no other words!\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "\n",
    "output_parser = DatetimeOutputParser()\n",
    "print(output_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75793685-9cfd-4caa-989d-7423ec35d66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: ¿Cuándo es el día de la declaración de independencia de los EEUU?\n",
      "Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\n",
      "\n",
      "Examples: 0038-11-25T01:11:44.523256Z, 0395-08-05T16:17:13.266100Z, 1540-03-26T05:46:22.363441Z\n",
      "\n",
      "Return ONLY this string, no other words!\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{request}\\n{format_instructions}\"\n",
    "human_prompt=HumanMessagePromptTemplate.from_template(template_text)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([human_prompt])\n",
    "print(chat_prompt.format(request=\"¿Cuándo es el día de la declaración de independencia de los EEUU?\",\n",
    "                   format_instructions=output_parser.get_format_instructions()\n",
    "                   ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cb14985-a95b-4ac2-8b81-3ce3fa1b790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "solicitud_completa = chat_prompt.format_prompt(request=\"¿Cuándo es el día de la declaración de independencia de los EEUU?\",\n",
    "                   format_instructions=output_parser.get_format_instructions()\n",
    "                   ).to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fefe677c-9f29-4ddf-a638-59377babbe62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7 de julio de 1776'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = chat.invoke(solicitud_completa)\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65da8fe0-c699-4c53-ba81-d8ed4f34188a",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutputParserException",
     "evalue": "Could not parse datetime string: 7 de julio de 1776\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mD:\\MisTrabajos\\IA_generativa\\venv\\Lib\\site-packages\\langchain\\output_parsers\\datetime.py:50\u001b[0m, in \u001b[0;36mDatetimeOutputParser.parse\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mD:\\programas\\Anaconda\\Lib\\_strptime.py:568\u001b[0m, in \u001b[0;36m_strptime_datetime\u001b[1;34m(cls, data_string, format)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a class cls instance based on the input string and the\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;124;03mformat string.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 568\u001b[0m tt, fraction, gmtoff_fraction \u001b[38;5;241m=\u001b[39m \u001b[43m_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m tzname, gmtoff \u001b[38;5;241m=\u001b[39m tt[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n",
      "File \u001b[1;32mD:\\programas\\Anaconda\\Lib\\_strptime.py:349\u001b[0m, in \u001b[0;36m_strptime\u001b[1;34m(data_string, format)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found:\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime data \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m does not match format \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    350\u001b[0m                      (data_string, \u001b[38;5;28mformat\u001b[39m))\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_string) \u001b[38;5;241m!=\u001b[39m found\u001b[38;5;241m.\u001b[39mend():\n",
      "\u001b[1;31mValueError\u001b[0m: time data '7 de julio de 1776' does not match format '%Y-%m-%dT%H:%M:%S.%fZ'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\MisTrabajos\\IA_generativa\\venv\\Lib\\site-packages\\langchain\\output_parsers\\datetime.py:52\u001b[0m, in \u001b[0;36mDatetimeOutputParser.parse\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m datetime\u001b[38;5;241m.\u001b[39mstrptime(response\u001b[38;5;241m.\u001b[39mstrip(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse datetime string: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     54\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mOutputParserException\u001b[0m: Could not parse datetime string: 7 de julio de 1776\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE "
     ]
    }
   ],
   "source": [
    "output_parser.parse(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03014ea7-f90f-49ef-8d17-b2b2faad06ec",
   "metadata": {},
   "source": [
    "### Métodos para solucionar problemas de parcheo.\n",
    "\n",
    "Hay ocasiones en las que no obtenemos la salida que nosotros queremos y existen algunas soluciones para dar solución a esos problemas.\n",
    "\n",
    "#### Auto-Fix Parser.\n",
    "```{index} Auto-Fix parser\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a748d150-879f-4109-9db3-1fb11fa2b67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7 de julio de 1776'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import OutputFixingParser\n",
    "\n",
    "output_parser_dates = DatetimeOutputParser()\n",
    "\n",
    "misformatted = result.content\n",
    "\n",
    "misformatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03125a04-5a61-43a0-bdfd-22bf943c366c",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutputParserException",
     "evalue": "Could not parse datetime string: from datetime import datetime\nimport pytz\n\nstring = \"1776-07-04\"\ndt_object = datetime.strptime(string, \"%d-%m-%Y\")\nprint(dt_object.astimezone(pytz.UTC).strftime('%Y-%m-%dT%H:%M:%S.%fZ'))\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mD:\\MisTrabajos\\IA_generativa\\venv\\Lib\\site-packages\\langchain\\output_parsers\\datetime.py:50\u001b[0m, in \u001b[0;36mDatetimeOutputParser.parse\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mD:\\programas\\Anaconda\\Lib\\_strptime.py:568\u001b[0m, in \u001b[0;36m_strptime_datetime\u001b[1;34m(cls, data_string, format)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a class cls instance based on the input string and the\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;124;03mformat string.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 568\u001b[0m tt, fraction, gmtoff_fraction \u001b[38;5;241m=\u001b[39m \u001b[43m_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m tzname, gmtoff \u001b[38;5;241m=\u001b[39m tt[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n",
      "File \u001b[1;32mD:\\programas\\Anaconda\\Lib\\_strptime.py:349\u001b[0m, in \u001b[0;36m_strptime\u001b[1;34m(data_string, format)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found:\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime data \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m does not match format \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    350\u001b[0m                      (data_string, \u001b[38;5;28mformat\u001b[39m))\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_string) \u001b[38;5;241m!=\u001b[39m found\u001b[38;5;241m.\u001b[39mend():\n",
      "\u001b[1;31mValueError\u001b[0m: time data 'from datetime import datetime\\nimport pytz\\n\\nstring = \"1776-07-04\"\\ndt_object = datetime.strptime(string, \"%d-%m-%Y\")\\nprint(dt_object.astimezone(pytz.UTC).strftime(\\'%Y-%m-%dT%H:%M:%S.%fZ\\'))' does not match format '%Y-%m-%dT%H:%M:%S.%fZ'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m new_parser \u001b[38;5;241m=\u001b[39m OutputFixingParser\u001b[38;5;241m.\u001b[39mfrom_llm(parser\u001b[38;5;241m=\u001b[39moutput_parser_dates, llm\u001b[38;5;241m=\u001b[39mchat)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mnew_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmisformatted\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\MisTrabajos\\IA_generativa\\venv\\Lib\\site-packages\\langchain\\output_parsers\\fix.py:73\u001b[0m, in \u001b[0;36mOutputFixingParser.parse\u001b[1;34m(self, completion)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries:\n\u001b[1;32m---> 73\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         retries \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mD:\\MisTrabajos\\IA_generativa\\venv\\Lib\\site-packages\\langchain\\output_parsers\\fix.py:70\u001b[0m, in \u001b[0;36mOutputFixingParser.parse\u001b[1;34m(self, completion)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m retries \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries:\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 70\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries:\n",
      "File \u001b[1;32mD:\\MisTrabajos\\IA_generativa\\venv\\Lib\\site-packages\\langchain\\output_parsers\\datetime.py:52\u001b[0m, in \u001b[0;36mDatetimeOutputParser.parse\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m datetime\u001b[38;5;241m.\u001b[39mstrptime(response\u001b[38;5;241m.\u001b[39mstrip(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse datetime string: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     54\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mOutputParserException\u001b[0m: Could not parse datetime string: from datetime import datetime\nimport pytz\n\nstring = \"1776-07-04\"\ndt_object = datetime.strptime(string, \"%d-%m-%Y\")\nprint(dt_object.astimezone(pytz.UTC).strftime('%Y-%m-%dT%H:%M:%S.%fZ'))\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE "
     ]
    }
   ],
   "source": [
    "new_parser = OutputFixingParser.from_llm(parser=output_parser_dates, llm=chat)\n",
    "new_parser.parse(misformatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bdfa90-eed8-4deb-8846-3ef57914eec3",
   "metadata": {},
   "source": [
    "#### System Promt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1250d2b9-50b7-4e33-b633-1e10e315e3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: Tienes que responder únicamente con un patrón de fechas\n",
      "Human: ¿Cuándo es el día de la declaración de independencia de los EEUU?\n",
      "Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\n",
      "\n",
      "Examples: 1061-10-31T05:22:14.373337Z, 1421-02-13T15:45:46.010590Z, 1718-04-22T19:32:31.046310Z\n",
      "\n",
      "Return ONLY this string, no other words!\n"
     ]
    }
   ],
   "source": [
    "system_prompt = SystemMessagePromptTemplate.from_template(\"Tienes que responder únicamente con un patrón de fechas\")\n",
    "template_text = \"{request}\\n{format_instructions}\"\n",
    "human_prompt=HumanMessagePromptTemplate.from_template(template_text)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_prompt,human_prompt])\n",
    "print(chat_prompt.format(request=\"¿Cuándo es el día de la declaración de independencia de los EEUU?\",\n",
    "                   format_instructions=output_parser_dates.get_format_instructions()\n",
    "                   ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad1f92ec-0628-4db5-8fd2-0bbed8128e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "solicitud_completa = chat_prompt.format_prompt(request=\"¿Cuándo es el día de la declaración de independencia de los EEUU?\",\n",
    "                   format_instructions=output_parser_dates.get_format_instructions()\n",
    "                   ).to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e200fc11-83ed-4455-9998-e6d3ab33185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat.invoke(solicitud_completa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78e62e16-96fa-446a-ac68-a3281e6fae13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1776-07-04T10:00:00.000000Z'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "907b1087-afa4-4b59-afbc-9e74cc3e0a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(1776, 7, 4, 10, 0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser_dates.parse(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bbb22b-e642-4af8-b795-ca582af71e17",
   "metadata": {},
   "source": [
    "Podemos ver que al final con esta última herramienta hemos podido solucionar los errores de parseo que obteníamos anteriormente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67afb9e2-1dc8-466a-a3d3-c9340828d795",
   "metadata": {},
   "source": [
    "## Serialización de Prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05331098-625b-4871-81f4-be72eb311f86",
   "metadata": {},
   "source": [
    "En un capítulo anterior, hemos visto cómo poder trabajar con los denominados Pompts de LangChain. En ciertas ocasiones y bajo determinadas circunstancias, pudiera ocurrir que esos prompts lo queramos guardar, paro por ejemplo utilizarlos para futuros trabajos o compartir con otras personas. En esta sección, vamos a ver cómo podemos conseguir todo esto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1269d55f-f661-48a2-a9ea-86d5a29b7bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, SystemMessagePromptTemplate,ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d39d26-8b69-4560-861a-7c38352d7da0",
   "metadata": {},
   "source": [
    "Creamos la plantilla y la guardamos con la denominación \"prompt.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fc4129d-f223-4ec9-915a-19524e7201ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plantilla = \"Pregunta: {pregunta_usuario}\\n\\nRespuesta: Vamos a verlo paso a paso.\"\n",
    "prompt = PromptTemplate(template=plantilla)\n",
    "prompt.save(\"prompt.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78acc7bb-90dd-44b0-8693-4609b1f74824",
   "metadata": {},
   "source": [
    "Una vez hecho todo esto, posteriormente podremos cargar y utilizar de nuevo esa plantilla, de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1601bbc3-8e75-4cb7-b02f-ec2af7474c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['pregunta_usuario'], input_types={}, partial_variables={}, template='Pregunta: {pregunta_usuario}\\n\\nRespuesta: Vamos a verlo paso a paso.')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import load_prompt\n",
    "prompt_cargado = load_prompt('prompt.json')\n",
    "prompt_cargado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
