{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b7d7fbb-ae49-4e73-aaef-dbff99867e58",
   "metadata": {},
   "source": [
    "# Los Agentes en LangChain\n",
    "```{index} Agentes, ReAct\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2868bed-8546-4131-86c2-e4fb6ad8ec40",
   "metadata": {},
   "source": [
    "Los Agentes son una pieza importante y potente de LangChain. Dentro de este apartado, vamos a ver los siguientes aspectos:\n",
    "\n",
    "¿Qué son los agentes y su funcionamiento?\n",
    "¿Cómo crear agentes asistidos con motores de búsqueda?\n",
    "¿Cómo crear agentes programadores de código y conversacionales?\n",
    "¿Cómo usar herramientas personalizadas por los agentes?\n",
    "¿Cómo crear potentes agentes reales?\n",
    "\n",
    "Los agentes son una de las partes más novedosas de LangChain , pero ofrecen un enorme potencial para aplicaciones basadas en LLM, y además de una manera muy sencilla.\n",
    "\n",
    "Al combinar lo que ya aprendimos sobre Model IO, conexiones de datos y cadenas, ya hemos abordado aplicaciones similares a agentes, pero los agentes facilitan la creación de estas aplicaciones siendo además más robustas.\n",
    "\n",
    "Básicamente, los agentes permiten a los LLM conectarse a herramientas (por ejemplo, Wikipedia, Calculadora, Búsqueda de Google, etc.) y llevar a cabo un enfoque estructurado para completar una **tarea basada en ReAct** (razonamiento y actuación).\n",
    "\n",
    "ReAct es un enfoque de inteligencia artificial que combina **razonamiento (Reasoning) y acción (Acting)** para mejorar la toma de decisiones y la interacción con el entorno. Se utiliza en modelos de lenguaje y agentes de IA para mejorar su capacidad de resolver problemas de manera más eficiente.\n",
    "\n",
    "##  ¿Cómo funciona ReAct?\n",
    "El enfoque ReAct permite a un modelo de IA no solo **generar respuestas**, sino también **razonar sobre ellas y actuar en consecuencia**. Se basa en un ciclo de:\n",
    "1. **Pensamiento**: El modelo analiza la situación y razona sobre los pasos a seguir.\n",
    "2. **Acción**: Toma decisiones o consulta herramientas externas para obtener más información.\n",
    "3. **Observación**: Analiza los resultados de la acción y ajusta su razonamiento.\n",
    "\n",
    "##  ¿Para qué se usa?\n",
    "ReAct se usa en:\n",
    "- **Agentes conversacionales avanzados** (como asistentes inteligentes que pueden planificar y razonar).\n",
    "- **Sistemas de búsqueda y recuperación de información** (como IA que consulta bases de datos o la web).\n",
    "- **Juegos y simulaciones** (donde los agentes de IA deben tomar decisiones en entornos dinámicos).\n",
    "\n",
    "Al Agente se le asigna una tarea y puede razonar qué herramientas son apropiadas para usar y luego puede utilizar esos resultados para continuar a través de una cadena interna hasta que resuelva la tarea.\n",
    "\n",
    "Los agentes pueden ser extremadamente poderosos, especialmente si los combinamos con nuestras propias herramientas personalizadas.\n",
    "\n",
    "Imagina un Agente con acceso a documentos corporativos internos y la capacidad de realizar búsquedas relevantes externas, de repente, tendrás un asistente corporativo muy poderoso con información interna y externa para responder preguntas (de clientes, de personal interno,...).\n",
    "\n",
    "Ver el siguiente enlace:\n",
    "\n",
    "https://python.langchain.com/v0.1/docs/modules/agents/agent_types/\n",
    "\n",
    "Una lista de herramientas disponibles, se pueden encontrar en:\n",
    "\n",
    "https://python.langchain.com/v0.1/docs/integrations/tools/\n",
    "\n",
    "**NOTA**: 👌 💖 Existe el [frimware denominado CrewaAI](crewai) que nos permite crear agentes de una forma fácil y eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2a19c1-9169-4797-b930-41304ffd6555",
   "metadata": {},
   "source": [
    "## Primer caso de uso de los agentes Langchain\n",
    "\n",
    "Vamos a instalar primero la siguiente librería de Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c34018f-be26-4f05-b7e5-d41ecd9b3e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897c04bc-3aef-4a76-99c3-f01a3db2d472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, SystemMessagePromptTemplate,ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"llama3.2\",\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', # required, but unused,\n",
    "    temperature = 0\n",
    ")\n",
    "\n",
    "#Recomendable temperatura a 0 para que el LLM no sea muy creativo, vamos a tener muchas herramientas a nuestra disposición y queremos que \n",
    "#sea más determinista\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff044be-f1c0-4c4a-b916-a5a86ea4efc2",
   "metadata": {},
   "source": [
    "**NOTA**: según la documentación de LangChain, Al compilar con LangChain, todos los pasos se rastrearán automáticamente en LangSmith. Para configurar LangSmith, solo necesitamos configurar las siguientes variables de entorno:\n",
    "\n",
    "```\n",
    "export LANGCHAIN_TRACING_V2=\"true\"\n",
    "export LANGCHAIN_API_KEY=\"<your-api-key>\"\n",
    "```\n",
    "\n",
    "Para el siguiente agente se necesita tener instalada la siguiente librería\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12a16dc-036d-448c-9632-890ee04f70bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numexpr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d94beba-8b60-499d-998e-bbf31636a9dd",
   "metadata": {},
   "source": [
    "```{index} llm-math\n",
    "```\n",
    "\n",
    "A continuación definimos la herramientas a las que tiene accesos el agente. En este caso le estamos dando la herramienta de llm-math, que es una herramienta para el cálculo matemático."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3526dd4-4348-4f18-a15c-89337fe0d90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools,initialize_agent,AgentType,create_react_agent,AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f162901-06e7-438d-bd43-ac4d67efaf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm-math  es una herramienta para el cálculo matemático\n",
    "tools = load_tools([\"llm-math\",],llm=llm) \n",
    "#Lista de herramientas disponibles: https://python.langchain.com/v0.1/docs/integrations/tools/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4684a851-e7fe-4334-8872-ce55f92866b8",
   "metadata": {},
   "source": [
    "Podemos ver todos los tipos de agentes de los que podemos disponer, de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70a8013-7ade-4c67-8c96-27cdbc240e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(AgentType) #Vemos los diferentes tipos de agente a usar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5247eb24-cdc9-415b-bdcd-f84548907c31",
   "metadata": {},
   "source": [
    "Ahora ya creamos el agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9019b0e2-2413-4261-a2d8-278a3c75164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True,handle_parsing_errors=True) \n",
    "#Usamos el Zero Shot porque no estamos dando ningún ejemplo, solo pidiendo al agente hacer una tarea sin ejemplos previos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae25409-480e-4bb6-8c34-a78605610266",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = agent.run(\"Dime cuánto es 1598 multiplicado por 1983 y después sumas 1000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a57e82-e9d0-42bf-a37a-a205083787cd",
   "metadata": {},
   "source": [
    "Otra forma de utilizar un agente es mediante **create_react_agent**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111260e6-36a7-42f7-bdbe-4d869be626ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''Responde lo mejor que puedas usando tu conocimiento como LLM o bien las siguientes herramientas:\n",
    "{tools}\n",
    "Utiliza el siguiente formato:\n",
    "Pregunta: la pregunta de entrada que debes responder\n",
    "Pensamiento: siempre debes pensar en qué hacer\n",
    "Acción: la acción a realizar debe ser una de [{tool_names}]\n",
    "Entrada de acción: la entrada a la acción.\n",
    "Observación: el resultado de la acción.\n",
    "... (este Pensamiento/Acción/Introducción de Acción/Observación puede repetirse N veces,si no consigues el resultado tras 5 intentos, para la ejecución)\n",
    "Pensamiento: ahora sé la respuesta final\n",
    "Respuesta final: la respuesta final a la pregunta de entrada original\n",
    "¡Comenzar! Recuerda que no siempre es necesario usar las herramientas\n",
    "Pregunta: {input}\n",
    "Pensamiento:{agent_scratchpad}'''\n",
    "\n",
    "#agent_scratchpad: El agente no llama a una herramienta solo una vez para obtener la respuesta deseada, sino que tiene una estructura que llama a las\n",
    "#herramientas repetidamente hasta obtener la respuesta deseada. Cada vez que llama a una herramienta, en este campo se almacena cómo fue la \n",
    "#llamada anterior, información sobre la llamada anterior y el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd01ac27-6a47-4aec-91c4-f48fcc096e5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(template)\n",
    "agente = create_react_agent(llm,tools,prompt)\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agente,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    return_intermediate_steps=True,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "respuesta = agent_executor.invoke({\"input\": \"Dime cuánto es 1598 multiplicado por 1983\"})\n",
    "print(respuesta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edddb67-3189-4951-bb23-9f3bf74e5cb8",
   "metadata": {},
   "source": [
    "## Crear agente potenciado motor búsqueda.\n",
    "\n",
    "Ver el apéndice de este tema, para conocer los servicios que nos ofrece esta herramienta. Para poder utilizarla se necesita primero bajar la librería. Lo hacemos de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae02e74e-fb14-46c1-9faf-905ebe297297",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install google-search-results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45894b60-42da-4435-9e7b-2e148b98deaa",
   "metadata": {},
   "source": [
    "Utilizando este procedimiento tendremos acceso a motores de búsqueda que serán mucho más potentes que solo  disponer de la información del LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b034004-df2e-4951-92fa-c0ed8ced254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, SystemMessagePromptTemplate,ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.agents import load_tools,initialize_agent,AgentType,create_react_agent,AgentExecutor\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"llama3.2\",\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', # required, but unused,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c61956-fec0-47c8-8f38-9fb347eb5a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leemos la api key para serpapi\n",
    "f = open('../SERPAPIKey.txt')\n",
    "serp_api_key = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22e01e9-c94e-49fa-b61c-d8607b8be59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definir variable de entorno para que funcione correctamente:\n",
    "import os\n",
    "os.environ[\"SERPAPI_API_KEY\"]=serp_api_key #Si no está definida el error nos dará el nombre de la variable de entorno que espera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3c356c-04bc-4f0c-a034-649f45ea54c8",
   "metadata": {},
   "source": [
    "Definimos las herramientas a las que el agente tendrá acceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5795440a-7d2a-4118-a714-34a90ca83f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le indicamos qu eutilice la herramienta serpapi, que ya tenemos conexión pues hemos indicado nuestra api-key\n",
    "tools = load_tools([\"serpapi\",\"llm-math\",],llm=llm)\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)\n",
    "\n",
    "agent.invoke(\"¿En qué año nació Einstein? ¿Cuál es el resultado de ese año multiplicado por 3?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced97222-12b0-4b78-b4d7-5f0af805bc10",
   "metadata": {},
   "source": [
    "## Creación de un agente programador de código.\n",
    "\n",
    "En este apartado vamos a crear un agente que genere código python para la tarea que nosotros le solicitemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7e26dd-0233-42e2-a838-ffe228f25e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, SystemMessagePromptTemplate,ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.agents import load_tools,initialize_agent,AgentType,create_react_agent,AgentExecutor\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"llama3.2\",\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', # required, but unused,\n",
    "    temperature = 0\n",
    ")\n",
    "\n",
    "#Recomendable temperatura a 0 para que el LLM no sea muy creativo, vamos a tener muchas herramientas a nuestra disposición y queremos que \n",
    "#sea más determinista"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26e7192-9581-46d5-9b81-a7d6198f67e7",
   "metadata": {},
   "source": [
    "Importamos las siguientes librerías concretas para realizar estos trabajos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5676e33d-95c5-4741-99f7-cab0362f3e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe7a3e6-4304-4984-81a7-e3644a76f12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.agents.agent_toolkits import create_python_agent  # agente para crear código python\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0b25b8-8631-4f69-823e-3efb5073b4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos el agente\n",
    "agent = create_python_agent(tool=PythonREPLTool(),\n",
    "                           llm=llm,\n",
    "                           agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daa4bd9-aaeb-422b-8cd7-f0ffeeb26e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tenemos la siguiente lista de python desordenada con la que vamos a trabajar después\n",
    "lista_ejemplo = [3,1,5,3,5,6,7,3,5,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6309fb-3428-4422-a7b4-e6941de21fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacemos trabajar al agente\n",
    "agent.invoke(f'''ordena la lista {lista_ejemplo}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a70beaa-d7ac-454b-a650-48f750022b3c",
   "metadata": {},
   "source": [
    "La salida anterior ha generado una salida nula debido a que se ha excedido el tiempo de ejecución. Ello es debido a las limitaciones del equipo local con el que se está trabajando.\n",
    "\n",
    "Ahora vamos a ver otro ejemplo pero utilizando un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7acadc-9f9e-4fd8-a752-556a6b7111a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46df99d2-3920-4f55-b5fd-067ee23f0aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('datos_ventas_small.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2334ec92-eddb-4e42-9662-697408a24a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke(f'''¿Qué sentencias de código tendría que ejecutar para obtener la suma de venta total agregada por Línea de Producto? Este sería el dataframe {df}, no tienes que ejecutar la sentencia, solo pasarme el código a ejecutar''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f16fac-89ac-4a27-878d-87fcdccb29c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Línea Producto')['Venta total'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b160a48b-0186-4a41-81ab-7c14d73a85d2",
   "metadata": {},
   "source": [
    "Como sugerencia, es mejor pedir la instrucción de python para conseguir el objetivo, que no que te de directamente el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01371792-9229-4c3b-a66e-22a3bf0fa6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke(f'''¿Qué sentencias de código tendría que ejecutar para tener una visualización con la librería Seaborn que agregue a nivel de Línea de Producto el total de venta? Este sería el dataframe {df}, recuerda que no tienes que ejecutar la sentencia, solo pasarme el código a ejecutar''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32711ce-155a-4153-89c4-e1e1e003f14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de369f5-96cb-4bc2-b18f-3ddbc2d3055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.barplot(x='ID', y='Venta total', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e671836-ecf2-4213-a94e-783f0cd13b55",
   "metadata": {},
   "source": [
    "## Crear herramientas personalizadas.\n",
    "\n",
    "Podemos definir nuestras propias herramientas ( tools ) para ser usadas por el agente.\n",
    "\n",
    "Es muy importante definir bien el docstring (descripción de la función) puesto que en base a ello el agente seleccionará o no esa herramienta.\n",
    "\n",
    "El uso de herramientas personalizadas expande el uso de los agentes, podríamos incluso definir herramientas que conecten con APIs internas de nuestra empresa para determinadas tareas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b302f5-6958-4eed-a922-9c318cf7c5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, SystemMessagePromptTemplate,ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.agents import load_tools,initialize_agent,AgentType,create_react_agent,AgentExecutor\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"llama3.2\",\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', # required, but unused,\n",
    "    temperature = 0\n",
    ")\n",
    "\n",
    "#Recomendable temperatura a 0 para que el LLM no sea muy creativo, vamos a tener muchas herramientas a nuestra disposición y queremos que \n",
    "#sea más determinista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92239232-d13b-4964-bb63-836b203d42cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos nuestra herramienta personalizada\n",
    "from langchain.agents import tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e3aa43-c69a-421b-bcee-47a99003bd2a",
   "metadata": {},
   "source": [
    "Definimos la función que implementa la herramienta que va a utilizar el agente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78754142-f189-4366-b24a-b668fd0a53d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def persona_amable (text: str) -> str:\n",
    "    '''Retorna la persona más amable. Se espera que la entrada esté vacía \"\" \n",
    "    y retorna la persona más amable del universo'''\n",
    "    return \"Miguel Celebres\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1000fdf3-3c9e-4c2d-852d-c7749f0019d8",
   "metadata": {},
   "source": [
    "El LLM va a consultar del docstring de la función anterior, por si necesita utilizar esa herramienta personalizada para construir su respuesta.\n",
    "\n",
    "Primero vamos a realizar el ejemplo, sin utilizar esa herramienta personalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5213d8d8-00d9-413a-a9f9-fc3396333896",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"wikipedia\",\"llm-math\",],llm=llm)\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)\n",
    "agent.invoke(\"¿Quién es la persona más amable del universo?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c1dd56-c6fa-4a49-92db-9a18e493afbb",
   "metadata": {},
   "source": [
    "Ahora vamos a indicar que utilice la herramienta personalziada que hemos construido anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9a0bb6-253d-43d1-98eb-45491d21b37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = tools + [persona_amable]\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)\n",
    "agent.invoke(\"¿Quién es la persona más amable del universo?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b7a641-8391-4b9d-9a20-230beb12ce1d",
   "metadata": {},
   "source": [
    "Ahora vamos a ver otro ejemplo. En este caso, como nos podemos conectar a una determinada API interna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac608c6c-c8e8-45c7-9b5e-0ebf7b88cbc2",
   "metadata": {},
   "source": [
    "```python \n",
    "@tool\n",
    "def nombre_api_interna(text: str) -> str:\n",
    "    '''Conecta a la API_xx que realiza la tarea xx, debes usar esta API Key'''\n",
    "    ##Definir conexión a la API interna y devolver un resultado\n",
    "    return resultado\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169f3c04-9497-4edf-b456-1746919b40d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Supongamos que queremso consultar la hora actual sin más."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f381f1a-6f5c-4ddf-865c-d20e24d09982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solicitud con las herramientas actuales no proporciona el resultado que queremos\n",
    "agent.invoke(\"¿Cuál es la hora actual?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17efd689-0b11-4ab7-bd33-dfce9cb4f2d7",
   "metadata": {},
   "source": [
    "Lo que vamos a hacer es definir una herramienta personalizada que nos resuelva este problema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb994a11-265b-4739-acaa-eca8382bc7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "@tool\n",
    "def hora_actual(text: str)->str:\n",
    "    '''Retorna la hora actual, debes usar esta función para cualquier consulta sobre la hora actual. Para fechas que no sean\n",
    "    la hora actual, debes usar otra herramienta. La entrada está vacía y la salida retorna una string'''\n",
    "    return str(datetime.now())\n",
    "\n",
    "tools = tools + [hora_actual]\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True, handle_parsing_errors=True)\n",
    "\n",
    "# Solicitud con las herramientas actuales SÍ proporciona el resultado que queremos\n",
    "agent.invoke(\"¿Cuál es la hora actual?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c694ac-f9c0-4646-bd92-e8a434122a52",
   "metadata": {},
   "source": [
    "## Agentes conversacionales con memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce361c66-0483-4914-8046-5ae2b57f57d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, SystemMessagePromptTemplate,ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.agents import load_tools,initialize_agent,AgentType,create_react_agent,AgentExecutor\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"llama3.2\",\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', # required, but unused,\n",
    "    temperature = 0\n",
    ")\n",
    "\n",
    "#Recomendable temperatura a 0 para que el LLM no sea muy creativo, vamos a tener muchas herramientas a nuestra disposición y queremos que \n",
    "#sea más determinista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e48e7c-1042-459e-8110-b6869d6a3788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e896869e-0190-4f98-ab9b-cbe00bfd3906",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\") #ponemos una denominada clave a la memoria \"chat_history\"\n",
    "\n",
    "tools = load_tools([\"wikipedia\",\"llm-math\",],llm=llm)\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,memory=memory,verbose=True)\n",
    "\n",
    "agent.invoke(\"Dime 5 productos esenciales para el mantenimiento del vehículo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e006be19-233f-4f32-9548-a897f42492f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a poner a prueba la memoria\n",
    "agent.invoke(\"Necesito la respuesta anterior en castellano\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5dea87-4f93-4acd-b9c5-142ab57bd921",
   "metadata": {},
   "source": [
    "## Cración Agente Chatbot con memoria.\n",
    "\n",
    "Vamos acrear un Agente Chatbot con memoria a partir de sistema RAG con nuestra base de datos vectorial. Este agente va a combinar el potencial del BD vectorizadas con nuestros propios documentos y el resto de herramientas.\n",
    "\n",
    "El agente debe verificar si la herramienta apropiada es la personalizada que creemos que obtendrá datos de la BBDD Vectorial o, sin embargo, debe usar otras herramientas como Wikipedia para consultar información o bien el propio conocimiento del LLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329b5394-52b9-4782-adf9-604889c0e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, SystemMessagePromptTemplate,ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.agents import load_tools,initialize_agent,AgentType,create_react_agent,AgentExecutor\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"llama3.2\",\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', # required, but unused,\n",
    "    temperature = 0\n",
    ")\n",
    "\n",
    "#Recomendable temperatura a 0 para que el LLM no sea muy creativo, vamos a tener muchas herramientas a nuestra disposición y queremos que \n",
    "#sea más determinista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9c06f9-c044-44dd-bf80-109377294386",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Podríamos establecer que tuviera memoria\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\") #ponemos una denominada clave a la memoria \"chat_history\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd01227-fc55-4887-861c-1947990b8d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89e2d2b-1d9e-4f39-b9ff-75d0e38cffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caragamos nuestros datos de una BD vectorial\n",
    "\n",
    "#funcion_embedding = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "funcion_embedding = OllamaEmbeddings(model=\"llama3.2\")\n",
    "\n",
    "persist_path=\"BD/ejemplosk_embedding_db\"\n",
    "vector_store_connection = SKLearnVectorStore(embedding=funcion_embedding, persist_path=persist_path, serializer=\"parquet\")\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=vector_store_connection.as_retriever())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9d7a1c-9ba5-4d15-8ed0-fdfe5076930e",
   "metadata": {},
   "source": [
    "Ahora vamos a definir una herramienta personalizada apoyada en la base de datos vectorial, de tal manera que el agente pueda utilizar esta herramienta que hemos definido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14c32bb-9b2f-4d5e-bee4-600878aafc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "@tool\n",
    "def consulta_interna(text: str) -> str:\n",
    "    '''Retorna respuestas sobre la historia de España. Se espera que la entrada sea una cadena de texto\n",
    "    y retorna una cadena con el resultado más relevante. Si la respuesta con esta herramienta es relevante,\n",
    "    no debes usar ninguna herramienta más ni tu propio conocimiento como LLM'''\n",
    "    compressed_docs = compression_retriever.invoke(text)\n",
    "    resultado = compressed_docs[0].page_content\n",
    "    return resultado\n",
    "\n",
    "tools = load_tools([\"wikipedia\",\"llm-math\"],llm=llm)\n",
    "tools=tools+[consulta_interna]\n",
    "\n",
    "#ahora ya tenemos nuestra herramienta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2213f82-051d-4cc8-b10a-3c3682717d7d",
   "metadata": {},
   "source": [
    "Ahora ya estamos en condiciones de crear el agente y lo utilizamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7a494d-af1e-497a-b001-68999a1beaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, llm, agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,memory=memory,verbose=True)\n",
    "# esto lo debería coger de nuestra herramienta personalizada\n",
    "agent.invoke(\"¿Qué periodo abarca cronológicamente en España el siglo de oro?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e5907a-2087-429c-b615-30bd5dfdfb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke(\"¿Qué pasó durante la misma etapa en Francia?\") #Gracias a tener memoria compara en esas fechas qué ocurrió en Francia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993e0dee-d2b7-4205-a64c-3f10e1b17b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke(\"¿Cuáles son las marcas de vehículos más famosas hoy en día?\") #Pregunta que no podemos responder con nuestra BD Vectorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c85bc7-bca6-4aea-9372-43814ece9bb6",
   "metadata": {},
   "source": [
    "*NOTA:* 🙋‍♂️😅 Como puede verse, los resultados que obtenemos no son los que buscamos, pero ello es debido a las limitaciones computacionales con las que estamos trabajando, por lo que este método es más bien didáctico y se expone para su conocimiento. En un mundo real, se debe utilizar un sistema computacional mucho más potente para obtener resultados acorde con lo que buscamos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76e9dd0-fdb9-4a5b-8de8-2dff277d0775",
   "metadata": {},
   "source": [
    "## Agente para análisis automático de SQL.\n",
    "\n",
    "En este apartado vamos a crear un agente que haga consultas SQL a la base de datos, pero las consultas se las pedimos en lenguaje natural, no SQL. 😲🤑. En concreto lo que vamos a pedir es lo siguiente: ¿Cuántas ventas ha habido en el primer trimestre del 2025?, que equivale a la siguiente consulta:\n",
    "\n",
    "```\n",
    "SELECT SUM(ventas) AS total_ventas\n",
    "FROM ventas\n",
    "WHERE fecha >= '2025_01-01' AND fecha < '2025-04-01';\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd96c354-7f1b-48b2-a884-681bc324fae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, SystemMessagePromptTemplate,ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.agents import load_tools,initialize_agent,AgentType,create_react_agent,AgentExecutor\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"llama3.2\",\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', # required, but unused,\n",
    "    temperature = 0\n",
    ")\n",
    "\n",
    "#Recomendable temperatura a 0 para que el LLM no sea muy creativo, vamos a tener muchas herramientas a nuestra disposición y queremos que \n",
    "#sea más determinista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852e9175-7fa6-4df5-8df7-883fa6fd54cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6440950-7123-445d-a0ff-b96feec5f12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector #pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4232bec7-9b0e-49a1-ab41-d8a098416fd8",
   "metadata": {},
   "source": [
    "Para desarrollar y ejecutar este caso de uso, se neceita tener isntalado en nuestro equipo un servidor de base de datos MySql. Como no es el caso, nos vamos a limitar a mostrar el código, ya que todos los conceptos que en él se desarrollan, ya se han expuestos en capítulos anteriores.\n",
    "\n",
    "```python\n",
    "f = open('../password_sql.txt')\n",
    "pass_sql = f.read()\n",
    "# Configuración de la conexión a la base de datos\n",
    "config = {\n",
    "    'user': 'root',       \n",
    "    'password': pass_sql, \n",
    "    'host': '127.0.0.1',         \n",
    "    'database': 'world'          \n",
    "}\n",
    "\n",
    "\n",
    "# Conectar a la base de datos\n",
    "conn = mysql.connector.connect(**config)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Definir la consulta manualmente: tengo una base de datos mysql en mi computadora local denominada \"world\" y una tabla \"Country\" \n",
    "#sobre la que quiero hacer la suma de la población en la columna \"Population\" para el continente Asia (columna \"Continent\")\n",
    "query = \"\"\"\n",
    "    SELECT SUM(Population)\n",
    "    FROM Country\n",
    "    WHERE Continent = 'Asia';\n",
    "    \"\"\"\n",
    "\n",
    "# Ejecutar la consulta\n",
    "cursor.execute(query)\n",
    "result = cursor.fetchone()\n",
    "\n",
    "suma_poblacion = result[0] if result[0] is not None else 0\n",
    "print(f\"La suma de la población del continente Asia es: {suma_poblacion}\")\n",
    "\n",
    "\n",
    "# Creamos el agente SQL\n",
    "\n",
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "from langchain.sql_database import SQLDatabase\n",
    "\n",
    "# Crear una cadena de conexión a la base de datos MySQL\n",
    "connection_string = f\"mysql+mysqlconnector://{config['user']}:{config['password']}@{config['host']}/{config['database']}\"\n",
    "\n",
    "# Crear una instancia de la base de datos SQL\n",
    "db = SQLDatabase.from_uri(connection_string)\n",
    "\n",
    "agent = create_sql_agent(\n",
    "    llm,\n",
    "    db=db,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "agent.invoke(\"Dime la población total de Asia\")\n",
    "\n",
    "result = agent.invoke(\"Dime el promedio de la esperanza de vida por cada una de las regiones ordenadas de mayor a menor\")\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(result[\"output\"])\n",
    "\n",
    "# Para utilizar few-shoots para las consultas SQL: https://python.langchain.com/v0.1/docs/use_cases/sql/agents/\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9464c3af-bac2-4386-9dc4-e7f83222c101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cb218d-fe28-4b24-af53-c6532894daca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bf1539-f53b-49d2-9fad-cd4c75a639f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9decd9dd-5dae-464b-8d9f-5a382f81cc36",
   "metadata": {},
   "source": [
    "## Apéndice.\n",
    "```{index} serpapi\n",
    "```\n",
    "### Serpapi.\n",
    "\n",
    "\n",
    "\n",
    "**SerpApi** es una API que permite extraer datos de los resultados de búsqueda de Google y otros motores de búsqueda sin necesidad de realizar scraping manualmente. Facilita la obtención de resultados de Google Search, Google Images, Google News, Google Maps, Google Shopping, YouTube y más, de una manera estructurada y libre de bloqueos.  \n",
    "\n",
    "#### **¿Por qué usar SerpApi?**  \n",
    "1. **Evita bloqueos**: Google implementa restricciones y CAPTCHA para prevenir el scraping, pero SerpApi maneja esto automáticamente.  \n",
    "2. **Datos estructurados**: Los resultados se devuelven en formato JSON, lo que facilita su procesamiento.  \n",
    "3. **Compatibilidad con múltiples motores de búsqueda**: Además de Google, soporta Bing, DuckDuckGo, Yahoo, entre otros.  \n",
    "4. **Alta velocidad y escalabilidad**: Permite realizar múltiples solicitudes de búsqueda de forma eficiente.  \n",
    "\n",
    "#### **¿Cómo funciona?**  \n",
    "Para usar SerpApi, necesitas:  \n",
    "1. **Crear una cuenta** en [SerpApi](https://serpapi.com/).  \n",
    "2. **Obtener una API Key** para autenticar solicitudes.  \n",
    "3. **Realizar peticiones HTTP** al endpoint de búsqueda con los parámetros deseados.  \n",
    "\n",
    "#### **Ejemplo en Python**  \n",
    "Aquí tienes un ejemplo de cómo hacer una búsqueda en Google usando la API de SerpApi con Python:  \n",
    "\n",
    "```python\n",
    "import requests\n",
    "\n",
    "params = {\n",
    "    \"q\": \"ChatGPT\",\n",
    "    \"hl\": \"es\",\n",
    "    \"gl\": \"es\",\n",
    "    \"api_key\": \"TU_API_KEY\"\n",
    "}\n",
    "\n",
    "response = requests.get(\"https://serpapi.com/search\", params=params)\n",
    "data = response.json()\n",
    "\n",
    "print(data)\n",
    "```\n",
    "Este código devuelve los resultados de búsqueda de Google en JSON.  \n",
    "\n",
    "#### **Casos de uso**  \n",
    "- Monitoreo de rankings en SEO.  \n",
    "- Seguimiento de precios en Google Shopping.  \n",
    "- Extracción de datos de Google Maps para negocios locales.  \n",
    "- Automatización de investigaciones en Google News.\n",
    "\n",
    "**NOTA:** 👍 👌 Esta herramienta es de pago pero en el momento de redactar estas líneas, existe una versión gratuita que permite hacer 100 búsquedas al mes sin tener que pagar.\n",
    "\n",
    "* <a href=\"https://serpapi.com/\" target=\"_blank\"> Página oficial de serpapi </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2409b7-538a-40a9-9db7-d2e7882987b4",
   "metadata": {},
   "source": [
    "### Artículo muy interesante.\n",
    "```{index} Agentes\n",
    "```\n",
    "\n",
    "A continuación se indica un enlace para ver un artículo muy interesante sobre los agentes de LangChain\n",
    "\n",
    "* <a href=\"https://www.datacamp.com/es/tutorial/building-langchain-agents-to-automate-tasks-in-python\" target=\"_blank\"> Trabajar con Agentes en LangChain </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
