
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>3. Bases de datos en LangChain. &#8212; IA generativa</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'cuadernos/basesDatosLangchain';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="4. Introducción a las cadena en LangChain." href="cadenas.html" />
    <link rel="prev" title="2. Templates con LangChain." href="Templates.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../introduccion.html">
  
  
  
  
  
  
    <p class="title logo__title">IA generativa</p>
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">IA generativa</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="langchain.html">1. Langchain</a></li>
<li class="toctree-l1"><a class="reference internal" href="Templates.html">2. Templates en LangChain</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">3. Conectores a Bases de Datos</a></li>
<li class="toctree-l1"><a class="reference internal" href="cadenas.html">4. Las cadenas de LangChain</a></li>
<li class="toctree-l1"><a class="reference internal" href="memoria.html">5. La memoria en LangChain</a></li>
<li class="toctree-l1"><a class="reference internal" href="Agenteslangchain.html">6. Los Agentes en LangChain</a></li>
<li class="toctree-l1"><a class="reference internal" href="Agentes_RAG.html">7. Ejemplo de agente RAG</a></li>
<li class="toctree-l1"><a class="reference internal" href="ollama.html">8. Ollama</a></li>
<li class="toctree-l1"><a class="reference internal" href="embeddings.html">9. Cómo hacer embeding's</a></li>
<li class="toctree-l1"><a class="reference internal" href="assistants/introAsistentes.html">10. La Api de OpenAI.</a></li>

<li class="toctree-l1"><a class="reference internal" href="conpago.html">12. Métodos de pago</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">IA generativa (Apéndices)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="apendice.html">13. Apéndice</a></li>
<li class="toctree-l1"><a class="reference internal" href="videos.html">14. Vídeos interesantes</a></li>
<li class="toctree-l1"><a class="reference internal" href="apendices/Llama_2.html">15. Llama 2 en Colab</a></li>
<li class="toctree-l1"><a class="reference internal" href="apendices/ModelosNER.html">16. Named Entity Recognition(NER)</a></li>
<li class="toctree-l1"><a class="reference internal" href="apendices/GeneracionTexto.html">17. Auto-Completado de texto</a></li>
<li class="toctree-l1"><a class="reference internal" href="apendices/gradio.html">18. Gradio</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Casos de uso</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="casosUso/EjemploLangGraph.html">19. Ejemplo con LangGraph</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Índice de términos</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../genindex.html">Índice de términos</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">



<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Bases de datos en LangChain.</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cargadores-de-documentos">3.1. Cargadores de documentos.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cargar-documentos-de-tipo-csv">3.2. Cargar documentos de tipo CSV</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cargar-datos-html">3.3. Cargar datos HTML</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cargar-datos-pdf">3.4. Cargar datos PDF</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#caso-de-uso-resumir-un-documento">3.5. Caso de uso resumir un documento</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#integracion-con-otras-plataformas">3.6. Integración con otras plataformas.</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cargar-informaciones-de-wikipedia">3.6.1. Cargar informaciones de wikipedia.</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#transformacion-de-documentos">3.7. Transformación de documentos.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#incrustacion-de-texto-y-creacion-de-vectores-embeging">3.8. Incrustación de texto y creación de vectores (embeging)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#incrustacion-de-documentos">3.8.1. Incrustación de documentos.</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#almacenamiento-de-vectores-en-bd">3.9. Almacenamiento de vectores en BD.</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#busqueda-en-la-base-de-datos">3.9.1. Búsqueda en la Base de Datos.</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#recuprar-datos-de-una-bd">3.10. Recuprar datos de una BD.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#alternativa-con-chromadb">3.11. Alternativa con ChromaDB.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#anadir-nueva-informacion-a-la-bd-de-vectores">3.12. Añadir nueva información a la BD de vectores</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#comprension-y-optimizacion-de-resultados-a-partir-de-llms">3.13. Comprensión y optimización de resultados a partir de LLMs.</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#consulta-con-compresion-contextual-usando-llms">3.13.1. Consulta con compresión contextual usando LLMs.</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="bases-de-datos-en-langchain">
<h1><span class="section-number">3. </span>Bases de datos en LangChain.<a class="headerlink" href="#bases-de-datos-en-langchain" title="Link to this heading">#</a></h1>
<p>En este apartado vamos a ver los siguientes aspectos:</p>
<ul class="simple">
<li><p>¿Cómo cargar fuentes de datos de todo tipo con Langchain</p></li>
<li><p>¿Cómo transformar documentos y fragmentarlos?</p></li>
<li><p>¿Cómo convertir documentos en vectores a partir de incrustaciones embeddings</p></li>
<li><p>¿Cómo almacenar los datos (internos y externos) en una base de datos vectorizada?</p></li>
<li><p>¿Cómo realizar consultas a la base de datos vectorizada y mejorar los resultados con LLMs</p></li>
</ul>
<p>Comenzamos con el primer apartado, es decír, cómo poder cargar datos de múltiples fuentes.</p>
<section id="cargadores-de-documentos">
<h2><span class="section-number">3.1. </span>Cargadores de documentos.<a class="headerlink" href="#cargadores-de-documentos" title="Link to this heading">#</a></h2>
<p>Langchain viene con herramientas de carga integradas para cargar rápidamente archivos en su propio objeto Documento.</p>
<p>Muchos de estos cargadores requieren otras bibliotecas, por ejemplo, la carga de PDF requiere la biblioteca pypdf y la carga de HTML requiere la biblioteca Beautiful Soup . Asegurar de instalar las bibliotecas requeridas antes de usar el cargador (los cargadores informarán si no pueden encontrar las bibliotecas instaladas).</p>
<p>Entre otras librerias es muy conveniente tener instalada la  librería <em>Langchain community</em> para loaders en Python .</p>
<p>Para ver la documentación sobre los loaders de LangChain, se puede visitar el siguiente enlace:</p>
<p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/document_loaders/">https://python.langchain.com/v0.2/docs/integrations/document_loaders/</a></p>
<p>Procedemos a cargar las librerías e instanciar el modelo de tipo de chat</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">langchain</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.prompts</span><span class="w"> </span><span class="kn">import</span> <span class="n">PromptTemplate</span><span class="p">,</span> <span class="n">SystemMessagePromptTemplate</span><span class="p">,</span><span class="n">ChatPromptTemplate</span><span class="p">,</span> <span class="n">HumanMessagePromptTemplate</span>

<span class="n">chat</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;llama3.2&quot;</span><span class="p">,</span>
    <span class="n">base_url</span> <span class="o">=</span> <span class="s1">&#39;http://localhost:11434/v1&#39;</span><span class="p">,</span>
    <span class="n">api_key</span><span class="o">=</span><span class="s1">&#39;ollama&#39;</span><span class="p">,</span> <span class="c1"># required, but unused,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="cargar-documentos-de-tipo-csv">
<h2><span class="section-number">3.2. </span>Cargar documentos de tipo CSV<a class="headerlink" href="#cargar-documentos-de-tipo-csv" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain.document_loaders</span><span class="w"> </span><span class="kn">import</span> <span class="n">CSVLoader</span> <span class="c1">#pip install langchain-community en una terminal</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Cargamos el fichero CSV</span>
<span class="n">loader</span> <span class="o">=</span> <span class="n">CSVLoader</span><span class="p">(</span><span class="s1">&#39;Fuentes datos/datos_ventas_small.csv&#39;</span><span class="p">,</span><span class="n">csv_args</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;delimiter&#39;</span><span class="p">:</span> <span class="s1">&#39;;&#39;</span><span class="p">})</span>
<span class="c1">#Creamos el objeto &quot;data&quot; con los datos desde el cargador &quot;loader&quot;</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
<span class="c1">#print(data) #Vemos que se ha creado un documento por cada fila donde el campo page_content contiene los datos</span>
<span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">page_content</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="cargar-datos-html">
<h2><span class="section-number">3.3. </span>Cargar datos HTML<a class="headerlink" href="#cargar-datos-html" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain.document_loaders</span><span class="w"> </span><span class="kn">import</span> <span class="n">BSHTMLLoader</span> <span class="c1">#pip install beautifulsoup4 en una terminal</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">loader</span> <span class="o">=</span> <span class="n">BSHTMLLoader</span><span class="p">(</span><span class="s1">&#39;Fuentes datos/ejemplo_web.html&#39;</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
<span class="n">data</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">page_content</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="cargar-datos-pdf">
<h2><span class="section-number">3.4. </span>Cargar datos PDF<a class="headerlink" href="#cargar-datos-pdf" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain.document_loaders</span><span class="w"> </span><span class="kn">import</span> <span class="n">PyPDFLoader</span> <span class="c1">#pip install pypdf en una terminal</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">loader</span> <span class="o">=</span> <span class="n">PyPDFLoader</span><span class="p">(</span><span class="s1">&#39;Fuentes datos/Documento tecnologías emergentes.pdf&#39;</span><span class="p">)</span>
<span class="n">pages</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">load_and_split</span><span class="p">()</span>
<span class="nb">type</span><span class="p">(</span><span class="n">pages</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">pages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">page_content</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="caso-de-uso-resumir-un-documento">
<h2><span class="section-number">3.5. </span>Caso de uso resumir un documento<a class="headerlink" href="#caso-de-uso-resumir-un-documento" title="Link to this heading">#</a></h2>
<p>En este apartado vamos a ver un ejemplo concreto sobre como poder utilizar el poder la IA para hacer un resumen de un texto</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">contenido_pdf</span><span class="o">=</span><span class="n">pages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">page_content</span>
<span class="n">contenido_pdf</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">human_template</span> <span class="o">=</span> <span class="s1">&#39;&quot;Necesito que hagas un resumen del siguiente texto: </span><span class="se">\n</span><span class="si">{contenido}</span><span class="s1">&quot;&#39;</span>
<span class="n">human_prompt</span> <span class="o">=</span> <span class="n">HumanMessagePromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="n">human_template</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chat_prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">([</span><span class="n">human_prompt</span><span class="p">])</span>

<span class="n">chat_prompt</span><span class="o">.</span><span class="n">format_prompt</span><span class="p">(</span><span class="n">contenido</span><span class="o">=</span><span class="n">contenido_pdf</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">solicitud_completa</span> <span class="o">=</span> <span class="n">chat_prompt</span><span class="o">.</span><span class="n">format_prompt</span><span class="p">(</span><span class="n">contenido</span><span class="o">=</span><span class="n">contenido_pdf</span><span class="p">)</span><span class="o">.</span><span class="n">to_messages</span><span class="p">()</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">chat</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">solicitud_completa</span><span class="p">)</span>
<span class="n">result</span><span class="o">.</span><span class="n">content</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Resumir el documento completo</span>
<span class="c1">#Creamos una string concatenando el contenido de todas las páginas</span>
<span class="n">documento_completo</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
<span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="n">pages</span><span class="p">:</span>
    <span class="n">documento_completo</span> <span class="o">+=</span> <span class="n">page</span><span class="o">.</span><span class="n">page_content</span>  <span class="c1"># Supongamos que cada página tiene un atributo &#39;text&#39;</span>

<span class="nb">print</span><span class="p">(</span><span class="n">documento_completo</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">solicitud_completa</span> <span class="o">=</span> <span class="n">chat_prompt</span><span class="o">.</span><span class="n">format_prompt</span><span class="p">(</span><span class="n">contenido</span><span class="o">=</span><span class="n">documento_completo</span><span class="p">)</span><span class="o">.</span><span class="n">to_messages</span><span class="p">()</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">chat</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">solicitud_completa</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">result</span><span class="o">.</span><span class="n">content</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="integracion-con-otras-plataformas">
<h2><span class="section-number">3.6. </span>Integración con otras plataformas.<a class="headerlink" href="#integracion-con-otras-plataformas" title="Link to this heading">#</a></h2>
<p>Existen otros cargadores de documentos que son denominados “integraciones” y pueden ser considerados esencialmente lo mismo que los cargadores normales vistos en la sección anterior, pero con la salvedad y la ventaja de que están integrados con otras plataformas como por ejemplo:</p>
<ul class="simple">
<li><p>Plataforma de terceros (como Google Cloud, AWS, Google Drive, Dropbox,…)</p></li>
<li><p>Base de datos (como MongoDB)</p></li>
<li><p>Sitio web específico, como Wikipedia</p></li>
<li><p>Permiten cargar vídeos de Youtube (por ejemplo, crear una aplicación de preguntas y respuestas en base a vídeos de Youtube ), conversaciones de WhatsApp y un sinfín de posibilidades.</p></li>
</ul>
<p>Con todas estas integraciones, vamos a tener la ventaja de cargar esta información en una base de datos vectorial y después consultar esa información con todas las ventajas que esta información nos puede proporcionar.</p>
<p>La documentación sobre este tipo de cargadores (document loaders - integraciones), se tiene en este enlace:</p>
<p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/document_loaders/">https://python.langchain.com/v0.2/docs/integrations/document_loaders/</a></p>
<section id="cargar-informaciones-de-wikipedia">
<h3><span class="section-number">3.6.1. </span>Cargar informaciones de wikipedia.<a class="headerlink" href="#cargar-informaciones-de-wikipedia" title="Link to this heading">#</a></h3>
<p>A continuación vamos a mostrar un caso de usos que consiste en cargar información de la wikipedia. Como siempre cargamos los paquetes correspondientes y cargamos el chat.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">langchain</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.prompts</span><span class="w"> </span><span class="kn">import</span> <span class="n">PromptTemplate</span><span class="p">,</span> <span class="n">SystemMessagePromptTemplate</span><span class="p">,</span><span class="n">ChatPromptTemplate</span><span class="p">,</span> <span class="n">HumanMessagePromptTemplate</span>


<span class="n">chat</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;llama3.2&quot;</span><span class="p">,</span>
    <span class="n">base_url</span> <span class="o">=</span> <span class="s1">&#39;http://localhost:11434/v1&#39;</span><span class="p">,</span>
    <span class="n">api_key</span><span class="o">=</span><span class="s1">&#39;ollama&#39;</span><span class="p">,</span> <span class="c1"># required, but unused,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!pip install wikipedia</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain.document_loaders</span><span class="w"> </span><span class="kn">import</span> <span class="n">WikipediaLoader</span> <span class="c1"># pip install wikipedia en una terminal</span>
</pre></div>
</div>
</div>
</div>
<p>Definimos la siguiente función que es la que nos va a servir para obtener y ejecutar lo que necesitamos para hacer consultas apoyadas en la información que figura en la wikipedia.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">responder_wikipedia</span><span class="p">(</span><span class="n">persona</span><span class="p">,</span><span class="n">pregunta_arg</span><span class="p">):</span>
    <span class="c1"># Obtener artículo de wikipedia</span>
    <span class="n">docs</span> <span class="o">=</span> <span class="n">WikipediaLoader</span><span class="p">(</span><span class="n">query</span><span class="o">=</span><span class="n">persona</span><span class="p">,</span><span class="n">lang</span><span class="o">=</span><span class="s2">&quot;es&quot;</span><span class="p">,</span><span class="n">load_max_docs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span> <span class="c1">#parámetros posibles en: https://python.langchain.com/v0.2/docs/integrations/document_loaders/wikipedia/</span>
    <span class="c1"># Observar que el valor de &quot;persona&quot; lo pasamos como parámetro a la función</span>
    <span class="n">contexto_extra</span> <span class="o">=</span> <span class="n">docs</span><span class="o">.</span><span class="n">load</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">page_content</span> <span class="c1">#para que sea más rápido solo pásamos el primer documento [0] como contexto extra</span>
    
    <span class="c1"># Pregunta de usuario, que se la pasamos como parámetro de la función</span>
    <span class="n">human_prompt</span> <span class="o">=</span> <span class="n">HumanMessagePromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="s1">&#39;Responde a esta pregunta</span><span class="se">\n</span><span class="si">{pregunta}</span><span class="s1">, aquí tienes contenido extra:</span><span class="se">\n</span><span class="si">{contenido}</span><span class="s1">&#39;</span><span class="p">)</span>
    
    <span class="c1"># Construir prompt</span>
    <span class="n">chat_prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">([</span><span class="n">human_prompt</span><span class="p">])</span>
    
    <span class="c1"># Resultado</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">chat</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">chat_prompt</span><span class="o">.</span><span class="n">format_prompt</span><span class="p">(</span><span class="n">pregunta</span><span class="o">=</span><span class="n">pregunta_arg</span><span class="p">,</span><span class="n">contenido</span><span class="o">=</span><span class="n">contexto_extra</span><span class="p">)</span><span class="o">.</span><span class="n">to_messages</span><span class="p">())</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">responder_wikipedia</span><span class="p">(</span><span class="s2">&quot;José María Aznar&quot;</span><span class="p">,</span><span class="s2">&quot;¿En qué localidad nació?&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="transformacion-de-documentos">
<h2><span class="section-number">3.7. </span>Transformación de documentos.<a class="headerlink" href="#transformacion-de-documentos" title="Link to this heading">#</a></h2>
<p id="index-0">Hay que tener en cuenta que después de cargar un objeto Documento desde una fuente, terminará con cadenas de texto desde el campo page_content. Entonces puede haber situaciones en las que la longitud de las cadenas asó obtenidas pueden ser muy grandes  para alimentar un modelo (por ejemplo, límite de 8k tokens ~6k palabras). Para resolver este problema, Langchain proporciona <strong>transformadores de documentos</strong> que permiten dividir fácilmente cadenas del page_content en fragmentos (que se conocen como chunks).</p>
<p>Estos fragmentos servirán más adelante además como componentes útiles en forma de vectores a partir de una incrustación (embeddings ), que luego podremos buscar utilizando una similitud de distancia más adelante. Por ejemplo, si queremos alimentar un LLM con contexto adicional para que sirva como chatbot de preguntas y respuestas, si tenemos varios vectores guardados cada uno con una información diferente, la búsqueda será más rápida puesto que se hará un cálculo del vector guardado que tiene mayor similaridad en lugar de buscar en todos los datos globales.</p>
<p>Veamos ahora un ejemplo ilustrativo de cómo poder hacer todo esto. Para hacer esto vamos a cargar un documento bastante extenso y con mucha información.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;Fuentes datos/Historia España.txt&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
    <span class="n">texto_completo</span> <span class="o">=</span> <span class="n">file</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="c1"># Números de caracteres</span>
<span class="nb">len</span><span class="p">(</span><span class="n">texto_completo</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Como podemos ver es un documento bastante extenso y lo que vamos a hacer es dividirlo en trozos más pequeños, los cuales tienen la denominación de chunks.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain.text_splitter</span><span class="w"> </span><span class="kn">import</span> <span class="n">CharacterTextSplitter</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">text_splitter</span> <span class="o">=</span> <span class="n">CharacterTextSplitter</span><span class="p">(</span><span class="n">separator</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span><span class="n">chunk_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span> <span class="c1">#Indicamos que divida cuando se encuentra 1 salto de línea y trate de hacer fragmentos de 1000 caracteres</span>
<span class="c1"># Intenta hacer los chunks más o menos del tamaño que se le da, en este caso de 1000</span>
</pre></div>
</div>
</div>
</div>
<p>Existen muchas más posibilidades para hacer esto, las cuales se pueden ver en este enlace:
<a class="reference external" href="https://python.langchain.com/api_reference/text_splitters/character/langchain_text_splitters.character.CharacterTextSplitter.html">https://python.langchain.com/api_reference/text_splitters/character/langchain_text_splitters.character.CharacterTextSplitter.html</a></p>
<p>Entre estas posibilidaddes está una muy utilizada y es que los cuhunks puedan tener cierto solpamientos, es decir que las últimas palabras del chunk anterior, sean también las palabras del chunk siguiente. Este efecto lo conseguimos con la opción <em>chunk_overlap</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">texts</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="o">.</span><span class="n">create_documents</span><span class="p">([</span><span class="n">texto_completo</span><span class="p">])</span> <span class="c1">#Creamos documentos gracias al transformador</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">texts</span><span class="p">))</span> <span class="c1">#Verificamos el tipo del objeto obtenido</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">texts</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span> <span class="c1">#Verificamos el tipo de cada elemento</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">texts</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">texts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">page_content</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">texts</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Veamos la longitud de cada uno de los chunks que se han obtenido</span>
<span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">h</span><span class="o">.</span><span class="n">page_content</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="incrustacion-de-texto-y-creacion-de-vectores-embeging">
<h2><span class="section-number">3.8. </span>Incrustación de texto y creación de vectores (embeging)<a class="headerlink" href="#incrustacion-de-texto-y-creacion-de-vectores-embeging" title="Link to this heading">#</a></h2>
<p id="index-1"><strong>NOTA</strong>: <a class="reference internal" href="embeddings.html#embeding"><span class="std std-ref">En este otro apartado</span></a>, también se puede ver desde diferentes puntos de vista cómo poder trabajar con este tipo embeding.</p>
<p>De cara a trabajar con textos en IA, lo que se suele hacer es transformar esos textos en una representación de los mismos mediante una serie de vectores que contienen información semántica de esos textos. Langchain admite muchas incrustaciones de texto, que pueden convertir directamente texto en una representación vectorizada incrustada.</p>
<p>En resumen, los modelos incrustados crean una representación vectorial de un fragmento de texto . Puedes pensar en un vector como una matriz de números que captura el significado semántico del texto. Al representar el texto de esta manera, puede realizar operaciones matemáticas que le permiten hacer cosas como buscar otras partes del texto que tengan un significado más similar.</p>
<p><img alt="" src="../_images/embeding.PNG" /></p>
<p>Estos modelos de embeding que utiliza LangChain, se puede ver su explicación en el siguiente enlace:</p>
<p><a class="reference external" href="https://python.langchain.com/v0.2/docs/concepts/#embedding-models">https://python.langchain.com/v0.2/docs/concepts/#embedding-models</a></p>
<p><strong>NOTA</strong> : Los diferentes modelos de incrustación puede que no interactúen entre sí, lo que significa que necesitaría volver a incrustar un conjunto completo de documentos si cambiara de modelo de incrustación en el futuro. En este se indicará cómo utilizar OpenAI, pues es uno de los métodos más utilizados, pero como se intenta hacer una explicación de estos métodos desde un punto de vista didáctico, sin incurrir en costes, se utilizará ollama para hacer cuestiones prácticas sobre estos métodos.</p>
<p>Se aconseja al lector mirar estos enlaces:</p>
<ul class="simple">
<li><p><a href="https://python.langchain.com/docs/integrations/text_embedding/ollama/" target="_blank">Presentación de OllamaEmbeddings </a></p></li>
<li><p><a href="https://python.langchain.com/api_reference/ollama/embeddings/langchain_ollama.embeddings.OllamaEmbeddings.html" target="_blank">Api de OllamaEmbeddings </a></p></li>
</ul>
<p>A continuación se muestra un caso práctico sobre cómo utilizar todos estos procesos.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">langchain</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.prompts</span><span class="w"> </span><span class="kn">import</span> <span class="n">PromptTemplate</span><span class="p">,</span> <span class="n">SystemMessagePromptTemplate</span><span class="p">,</span><span class="n">ChatPromptTemplate</span><span class="p">,</span> <span class="n">HumanMessagePromptTemplate</span>

<span class="n">chat</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;llama3.2&quot;</span><span class="p">,</span>
    <span class="n">base_url</span> <span class="o">=</span> <span class="s1">&#39;http://localhost:11434/v1&#39;</span><span class="p">,</span>
    <span class="n">api_key</span><span class="o">=</span><span class="s1">&#39;ollama&#39;</span><span class="p">,</span> <span class="c1"># required, but unused,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Si quisiéramos hacer esto desde OpenAi, el código a utilizar sería el siguiente: (Se ha dejado comentado el código)</p>
<p><strong>NOTA</strong>: Para ver cómo empezar con OpenAi, se recomienda ver <a class="reference internal" href="conpago.html#pago"><span class="std std-ref">este apartado</span></a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#from langchain_openai import OpenAIEmbeddings</span>
<span class="c1"># embeddings = OpenAIEmbeddings(openai_api_key=api_key)</span>
<span class="c1"># texto = &quot;Esto es un texto enviado a OpenAI para ser incrustado en un vector n-dimensional&quot;</span>
<span class="c1">#embedded_text = embeddings.embed_query(texto)</span>
</pre></div>
</div>
</div>
</div>
<p>Sin embargo y con el fin de evitar costes, vamos a ver cómo haríamos estos embeding, utilizando ollama desde LangChain.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_ollama</span><span class="w"> </span><span class="kn">import</span> <span class="n">OllamaEmbeddings</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_ollama</span><span class="w"> </span><span class="kn">import</span> <span class="n">OllamaEmbeddings</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">OllamaEmbeddings</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;llama3.2&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">texto</span> <span class="o">=</span> <span class="s2">&quot;Este es el texto que vamos a vectorizar utilizando para ello llama que sale gratuito&quot;</span>
<span class="n">embedded_text</span> <span class="o">=</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">embed_query</span><span class="p">(</span><span class="n">texto</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">type</span><span class="p">(</span><span class="n">embedded_text</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">embedded_text</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Este mismo ejercicio pero de forma asíncrona</span>
<span class="n">embedded_text</span> <span class="o">=</span> <span class="k">await</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">aembed_query</span><span class="p">(</span><span class="n">texto</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Si quisiéramos hacer esto con varios textos deberíamos utilizar una expresión similar a la siguiente:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">input_texts</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Document 1...&quot;</span><span class="p">,</span> <span class="s2">&quot;Document 2...&quot;</span><span class="p">]</span>
<span class="n">vectors</span> <span class="o">=</span> <span class="n">embed</span><span class="o">.</span><span class="n">embed_documents</span><span class="p">(</span><span class="n">input_texts</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vectors</span><span class="p">))</span>
<span class="c1"># The first 3 coordinates for the first vector</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vectors</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="mi">3</span><span class="p">])</span>
</pre></div>
</div>
<section id="incrustacion-de-documentos">
<h3><span class="section-number">3.8.1. </span>Incrustación de documentos.<a class="headerlink" href="#incrustacion-de-documentos" title="Link to this heading">#</a></h3>
<p>A continuación se muestra un ejemplo, para ver cómo podemos hacer embedings de documentos, que es la situación real con la que nos encontraremos al trabajar con IA.</p>
<p>Lo primero que hacemos es cargar un documento de tipo CSV</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain.document_loaders</span><span class="w"> </span><span class="kn">import</span> <span class="n">CSVLoader</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">loader</span> <span class="o">=</span> <span class="n">CSVLoader</span><span class="p">(</span><span class="s1">&#39;Fuentes datos/datos_ventas_small.csv&#39;</span><span class="p">,</span><span class="n">csv_args</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;delimiter&#39;</span><span class="p">:</span> <span class="s1">&#39;;&#39;</span><span class="p">})</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
<span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#No podemos incrustar el objeto &quot;data&quot; puesto que es una lista de documentos, lo que espera es una string</span>
<span class="c1"># Ejecutar el siguiente comando nos daría un error</span>
<span class="c1">#embedded_docs = embeddings.embed_documents(data)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Creamos una comprensión de listas concatenando el campo &quot;page_content&quot; de todos los documentos existentes en la lista &quot;data&quot;</span>
<span class="p">[</span><span class="n">elemento</span><span class="o">.</span><span class="n">page_content</span> <span class="k">for</span> <span class="n">elemento</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">embedded_docs</span> <span class="o">=</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">embed_documents</span><span class="p">([</span><span class="n">elemento</span><span class="o">.</span><span class="n">page_content</span> <span class="k">for</span> <span class="n">elemento</span> <span class="ow">in</span> <span class="n">data</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Verificamos cuántos vectores a creado (1 por cada registro del fichero CSV con datos)</span>
<span class="nb">len</span><span class="p">(</span><span class="n">embedded_docs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Vemos un ejemplo del vector creado para el primer registro</span>
<span class="n">embedded_docs</span><span class="p">[</span><span class="mi">1</span><span class="p">][:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="almacenamiento-de-vectores-en-bd">
<span id="almacenamiento"></span><h2><span class="section-number">3.9. </span>Almacenamiento de vectores en BD.<a class="headerlink" href="#almacenamiento-de-vectores-en-bd" title="Link to this heading">#</a></h2>
<p id="index-2">Hasta ahora hemos creado incrustaciones ( embeddings ) en memoria RAM como una lista de Python. Estos embedings en el momento en que nos salgamos de la aplicación se pierden, entonces ¿cómo podemos asegurarnos de que estas incorporaciones persistan en alguna solución de almacenamiento más permanente?</p>
<p>Para conseguir que esta información quede almacenada para futuras consultas, utilizamos un almacén de vectores, también conocido como base de datos de vectores , sus aspectos claves:</p>
<ul class="simple">
<li><p>Puede almacenar grandes vectores de N dimensiones.</p></li>
<li><p>Puede indexar directamente un vector incrustado y asociarlo a su documento string</p></li>
<li><p>Se puede “consultar”, lo que permite una búsqueda de similitud de coseno entre un nuevo vector que no está en la base de datos y los vectores almacenados.</p></li>
<li><p>Puede agregar, actualizar o eliminar fácilmente nuevos vectores.</p></li>
<li><p>Al igual que con los LLM y los modelos de chat, Langchain ofrece muchas opciones diferentes para almacenes de vectores.</p></li>
<li><p>Usaremos una base de datos de vectores open source SKLearn , pero gracias a Langchain , la sintaxis es estándar para el resto de BD.</p></li>
</ul>
<p>Para hacer este tipo de persistencia LangChain nos ofrece una amplia variedad de Bases de datos, las cuales las podemos consultar utilizando el siguiente link:</p>
<p><a class="reference external" href="https://python.langchain.com/v0.2/docs/integrations/vectorstores/">https://python.langchain.com/v0.2/docs/integrations/vectorstores/</a></p>
<p>La metodología que se emplea para este tipo de persistencia de la información, de forma esquemática se puede ver en la siguiente ilustración:</p>
<p><img alt="" src="../_images/BD.PNG" /></p>
<p>Como ya hemos hecho en casos anteriores, y con la finalidad de mostrar como actuar cuando se quiere hacer este tipo de cosas en IA, a continuación se pasa a ilustrar todo esto con algún ejemplo totalmente práctico.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAIEmbeddings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.text_splitter</span><span class="w"> </span><span class="kn">import</span> <span class="n">CharacterTextSplitter</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.document_loaders</span><span class="w"> </span><span class="kn">import</span> <span class="n">TextLoader</span>
</pre></div>
</div>
</div>
</div>
<p>Cargamos el documento y lo dividimos</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Cargar el documento</span>
<span class="n">loader</span> <span class="o">=</span> <span class="n">TextLoader</span><span class="p">(</span><span class="s1">&#39;Fuentes datos/Historia España.txt&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf8&quot;</span><span class="p">)</span>
<span class="n">documents</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>

<span class="c1"># Dividir en chunks</span>
<span class="n">text_splitter</span> <span class="o">=</span> <span class="n">CharacterTextSplitter</span><span class="o">.</span><span class="n">from_tiktoken_encoder</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span> <span class="c1">#Otro método de split basándose en tokens</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="o">.</span><span class="n">split_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Procedemos a la creación de embedings</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">funcion_embedding</span> <span class="o">=</span> <span class="n">OllamaEmbeddings</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;llama3.2&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Para el almacenamiento, utilizamos <em>SKLearn Vector Store</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_community.vectorstores</span><span class="w"> </span><span class="kn">import</span> <span class="n">SKLearnVectorStore</span> <span class="c1">#pip install scikit-learn / pip install pandas pyarrow</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!pip install pandas pyarrow</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">persist_path</span><span class="o">=</span><span class="s2">&quot;./BD/ejemplosk_embedding_db&quot;</span>  <span class="c1">#ruta donde se guardará la BBDD vectorizada</span>

<span class="c1">#Creamos la BBDD de vectores a partir de los documentos y la función embeddings</span>
<span class="n">vector_store</span> <span class="o">=</span> <span class="n">SKLearnVectorStore</span><span class="o">.</span><span class="n">from_documents</span><span class="p">(</span>
    <span class="n">documents</span><span class="o">=</span><span class="n">docs</span><span class="p">,</span>
    <span class="n">embedding</span><span class="o">=</span><span class="n">funcion_embedding</span><span class="p">,</span>
    <span class="n">persist_path</span><span class="o">=</span><span class="n">persist_path</span><span class="p">,</span>
    <span class="n">serializer</span><span class="o">=</span><span class="s2">&quot;parquet&quot;</span><span class="p">,</span> <span class="c1">#el serializador o formato de la BD lo definimos como parquet</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fuerza a guardar los nuevos embeddings en el disco</span>
<span class="n">vector_store</span><span class="o">.</span><span class="n">persist</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Una vez ejecutado el anterior código, y apodemos ver en nuestro disco duro la base de datos creada en la carpeta BD y con denominación ejemplosk_embedding_db.</p>
<section id="busqueda-en-la-base-de-datos">
<h3><span class="section-number">3.9.1. </span>Búsqueda en la Base de Datos.<a class="headerlink" href="#busqueda-en-la-base-de-datos" title="Link to this heading">#</a></h3>
<p>Una vez creada la base de datos podremos ya hacer consultas de similitud de cadenas, para que nos encuentre en la BD los párrafos más similares al litereal que le pasamos. Además nos devuelve párrafos ordenados de mayor a menor similitud.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Creamos un nuevo documento que será nuestra &quot;consulta&quot; para buscar el de mayor similitud en nuestra Base de Datos de Vectores y devolverlo</span>
<span class="n">consulta</span> <span class="o">=</span> <span class="s2">&quot;dame información de la Primera Guerra Mundial&quot;</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">vector_store</span><span class="o">.</span><span class="n">similarity_search</span><span class="p">(</span><span class="n">consulta</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">docs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">page_content</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>El resultado que obtenemos no es lo que realmente estamos buscando, pero hay que tener en cuenta que estamos trabajando en modo local y con resursos muy limitados debido a los escasos recursos que los ordenadores personales tienen para este tipo de trabajos de IA. Muy posiblemente si esto lo hacemos utilizando el api-key de OpenAi el resultado hubiera sido más acertado y además más rápido</p>
</section>
</section>
<section id="recuprar-datos-de-una-bd">
<h2><span class="section-number">3.10. </span>Recuprar datos de una BD.<a class="headerlink" href="#recuprar-datos-de-una-bd" title="Link to this heading">#</a></h2>
<p>Una vez creada la base de datos, y como ya los datos se han persistido y están almacenados en la base de datos, podemos recuperar en cualquier momento la información de esa base de datos y hacer consultas sobre la misma. A continuación se muestra cómo poder hacer esto.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vector_store_connection</span> <span class="o">=</span> <span class="n">SKLearnVectorStore</span><span class="p">(</span>
    <span class="n">embedding</span><span class="o">=</span><span class="n">funcion_embedding</span><span class="p">,</span> <span class="n">persist_path</span><span class="o">=</span><span class="n">persist_path</span><span class="p">,</span> <span class="n">serializer</span><span class="o">=</span><span class="s2">&quot;parquet&quot;</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Una instancia de la BBDD de vectores se ha cargado desde &quot;</span><span class="p">,</span> <span class="n">persist_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vector_store_connection</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nueva_consulta</span> <span class="o">=</span> <span class="s2">&quot;¿Qué paso en el siglo de Oro?&quot;</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">vector_store_connection</span><span class="o">.</span><span class="n">similarity_search</span><span class="p">(</span><span class="n">nueva_consulta</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">docs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">page_content</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="alternativa-con-chromadb">
<h2><span class="section-number">3.11. </span>Alternativa con ChromaDB.<a class="headerlink" href="#alternativa-con-chromadb" title="Link to this heading">#</a></h2>
<p>La base de datos ChromaDB, también es muy utilizada para realizar este tipo de tareas.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!pip install langchain_chroma</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">chromadb</span> <span class="c1">#pip install chromadb en una terminal</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_chroma</span><span class="w"> </span><span class="kn">import</span> <span class="n">Chroma</span> <span class="c1">#pip install langchain_chroma en una terminal</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Cargar en ChromaDB</span>
<span class="c1">#db = Chroma.from_documents(docs, funcion_embedding,collection_name=&quot;langchain&quot;,persist_directory=&#39;./ejemplo_embedding_db&#39;)</span>
<span class="c1">#Se crean en el directorio persistente la carpeta con los vectores y otra con las string, aparte de una carpeta &quot;index&quot; que mapea vectores y strings</span>
<span class="c1"># Fuerzar a guardar los nuevos embeddings en el disco</span>
<span class="c1">#db.persist()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="anadir-nueva-informacion-a-la-bd-de-vectores">
<h2><span class="section-number">3.12. </span>Añadir nueva información a la BD de vectores<a class="headerlink" href="#anadir-nueva-informacion-a-la-bd-de-vectores" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Cargar documento y dividirlo</span>
<span class="n">loader</span> <span class="o">=</span> <span class="n">TextLoader</span><span class="p">(</span><span class="s1">&#39;Fuentes datos/Nuevo_documento.txt&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf8&quot;</span><span class="p">)</span>
<span class="n">documents</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">text_splitter</span> <span class="o">=</span> <span class="n">CharacterTextSplitter</span><span class="o">.</span><span class="n">from_tiktoken_encoder</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="o">.</span><span class="n">split_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Cargar en Chroma</span>
<span class="c1">#db = Chroma.from_documents(docs, embedding_function,persist_directory=&#39;./ejemplo_embedding_db&#39;)</span>
<span class="c1"># docs = db.similarity_search(&#39;insertar_nueva_búsqueda&#39;)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="comprension-y-optimizacion-de-resultados-a-partir-de-llms">
<h2><span class="section-number">3.13. </span>Comprensión y optimización de resultados a partir de LLMs.<a class="headerlink" href="#comprension-y-optimizacion-de-resultados-a-partir-de-llms" title="Link to this heading">#</a></h2>
<p>En el apartado anterior hemos visto cómo poder encontrar párrafos de un texto que se asimilan mucho a la consulta que estamos planteando. Pero el resultado que obtenemos no presenta el formato más adecuado para la respuesta que buscamos. En este apartado vamos a ver cómo podemos conseguir esto.</p>
<p>No estamos realizando compresión en el sentido tradicional, sino que utilizamos un LLM para tomar una salida de texto de un documento de mayor tamaño y la limpia / optimiza en una salida más corta y relevante.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain.document_loaders</span><span class="w"> </span><span class="kn">import</span> <span class="n">WikipediaLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAIEmbeddings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.text_splitter</span><span class="w"> </span><span class="kn">import</span> <span class="n">CharacterTextSplitter</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.document_loaders</span><span class="w"> </span><span class="kn">import</span> <span class="n">TextLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_community.vectorstores</span><span class="w"> </span><span class="kn">import</span> <span class="n">SKLearnVectorStore</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#cargamos documentos desde la wikipedia</span>
<span class="n">loader</span> <span class="o">=</span> <span class="n">WikipediaLoader</span><span class="p">(</span><span class="n">query</span><span class="o">=</span><span class="s1">&#39;Lenguaje Python&#39;</span><span class="p">,</span><span class="n">lang</span><span class="o">=</span><span class="s2">&quot;es&quot;</span><span class="p">)</span>
<span class="n">documents</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Obtenemos de esta manera un documento lo suficientemente grande como para poder trabajar con el para demostrar esta facilidad de LangChain</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Procedemos a dividir el documento</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># División en fragmentos</span>
<span class="n">text_splitter</span> <span class="o">=</span> <span class="n">CharacterTextSplitter</span><span class="o">.</span><span class="n">from_tiktoken_encoder</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="o">.</span><span class="n">split_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">funcion_embedding</span> <span class="o">=</span> <span class="n">OllamaEmbeddings</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;llama3.2&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">persist_path</span><span class="o">=</span><span class="s2">&quot;./BD/ejemplo_wiki_bd&quot;</span>  <span class="c1">#ruta donde se guardará la BBDD vectorizada</span>

<span class="c1">#Creamos la BBDD de vectores a partir de los documentos y la función embeddings</span>
<span class="n">vector_store</span> <span class="o">=</span> <span class="n">SKLearnVectorStore</span><span class="o">.</span><span class="n">from_documents</span><span class="p">(</span>
    <span class="n">documents</span><span class="o">=</span><span class="n">docs</span><span class="p">,</span>
    <span class="n">embedding</span><span class="o">=</span><span class="n">funcion_embedding</span><span class="p">,</span>
    <span class="n">persist_path</span><span class="o">=</span><span class="n">persist_path</span><span class="p">,</span>
    <span class="n">serializer</span><span class="o">=</span><span class="s2">&quot;parquet&quot;</span><span class="p">,</span> <span class="c1">#el serializador o formato de la BD lo definimos como parquet</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fuerza a guardar los nuevos embeddings en el disco</span>
<span class="n">vector_store</span><span class="o">.</span><span class="n">persist</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Hacemos una consulta normal de similitud coseno</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Creamos un nuevo documento que será nuestra &quot;consulta&quot; para buscar el de mayor similitud en nuestra Base de Datos de Vectores y devolverlo</span>
<span class="n">consulta</span> <span class="o">=</span> <span class="s2">&quot;¿Por qué el lenguaje Python se llama así?&quot;</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">vector_store</span><span class="o">.</span><span class="n">similarity_search</span><span class="p">(</span><span class="n">consulta</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">docs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">page_content</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Como podemos ver la respuesta obtenida ( como antes quizá sin mucho sentido para la pregunta formulada) presenta un aspecto que no es el más adecuado para la presentación a la persona que formula la pregunta. Por ello, a continuación vamos a ver cómo podemos reconducir esto para obtener un resultado  que se adapte más a nuestras pretensiones.</p>
<section id="consulta-con-compresion-contextual-usando-llms">
<h3><span class="section-number">3.13.1. </span>Consulta con compresión contextual usando LLMs.<a class="headerlink" href="#consulta-con-compresion-contextual-usando-llms" title="Link to this heading">#</a></h3>
<p>Para obtener el resultado pretendido, vamos a importar las siguientes librerías</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">langchain_openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.retrievers</span><span class="w"> </span><span class="kn">import</span> <span class="n">ContextualCompressionRetriever</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain.retrievers.document_compressors</span><span class="w"> </span><span class="kn">import</span> <span class="n">LLMChainExtractor</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;llama3.2&quot;</span><span class="p">,</span> <span class="c1">#el parámetro temperatura define la aleatoriedad de las respuestas, temperatura = 0 significa el mínimo de aleatoriedad</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">api_key</span><span class="o">=</span><span class="s1">&#39;ollama&#39;</span><span class="p">,</span> <span class="c1"># required, but unused,</span>
<span class="p">)</span> 
<span class="n">compressor</span> <span class="o">=</span> <span class="n">LLMChainExtractor</span><span class="o">.</span><span class="n">from_llm</span><span class="p">(</span><span class="n">llm</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">compression_retriever</span> <span class="o">=</span> <span class="n">ContextualCompressionRetriever</span><span class="p">(</span><span class="n">base_compressor</span><span class="o">=</span><span class="n">compressor</span><span class="p">,</span> <span class="n">base_retriever</span><span class="o">=</span><span class="n">vector_store</span><span class="o">.</span><span class="n">as_retriever</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">compressed_docs</span> <span class="o">=</span> <span class="n">compression_retriever</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;¿Por qué el lenguaje Python se llama así?&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">compressed_docs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">page_content</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./cuadernos"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="Templates.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">2. </span>Templates con LangChain.</p>
      </div>
    </a>
    <a class="right-next"
       href="cadenas.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">4. </span>Introducción a las cadena en LangChain.</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cargadores-de-documentos">3.1. Cargadores de documentos.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cargar-documentos-de-tipo-csv">3.2. Cargar documentos de tipo CSV</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cargar-datos-html">3.3. Cargar datos HTML</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cargar-datos-pdf">3.4. Cargar datos PDF</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#caso-de-uso-resumir-un-documento">3.5. Caso de uso resumir un documento</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#integracion-con-otras-plataformas">3.6. Integración con otras plataformas.</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cargar-informaciones-de-wikipedia">3.6.1. Cargar informaciones de wikipedia.</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#transformacion-de-documentos">3.7. Transformación de documentos.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#incrustacion-de-texto-y-creacion-de-vectores-embeging">3.8. Incrustación de texto y creación de vectores (embeging)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#incrustacion-de-documentos">3.8.1. Incrustación de documentos.</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#almacenamiento-de-vectores-en-bd">3.9. Almacenamiento de vectores en BD.</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#busqueda-en-la-base-de-datos">3.9.1. Búsqueda en la Base de Datos.</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#recuprar-datos-de-una-bd">3.10. Recuprar datos de una BD.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#alternativa-con-chromadb">3.11. Alternativa con ChromaDB.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#anadir-nueva-informacion-a-la-bd-de-vectores">3.12. Añadir nueva información a la BD de vectores</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#comprension-y-optimizacion-de-resultados-a-partir-de-llms">3.13. Comprensión y optimización de resultados a partir de LLMs.</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#consulta-con-compresion-contextual-usando-llms">3.13.1. Consulta con compresión contextual usando LLMs.</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Francisco Rodríguez
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>